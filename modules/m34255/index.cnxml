<document xmlns="http://cnx.rice.edu/cnxml">
  <title>Music, Biological Evolution, and the Brain</title>
<metadata xmlns:md="http://cnx.rice.edu/mdml">
  <md:content-id>m34255</md:content-id>
  <md:title>Music, Biological Evolution, and the Brain</md:title>
  <md:abstract/>
  <md:uuid>503336ec-bb38-4453-ba4e-5115d0a7c7b0</md:uuid>
</metadata>

<content>
    <section id="id1164177070277">
      <title>Abstract</title>
      <para id="id1164180777307">This essay offers a novel theoretical perspective on the evolution of music. At present, a number of adaptationist theories posit that the human capacity for music is a product of natural selection, reflecting the survival value of musical behaviors in our species’ past (e.g., Wallin et al., 2000). In sharp contrast, a prominent nonadaptationist theory of music argues that music is a human invention and is biologically useless (Pinker, 1997). I argue that research on music and the brain supports neither of these views. Contrary to adaptationist theories, neuroscientific research suggests that the existence of music can be explained without invoking any evolutionary-based brain specialization for musical abilities. And contrary to Pinker’s claim, neuroscience research suggests that music can be biologically powerful. By biologically powerful, I mean that musical behaviors (e.g., playing, listening) can have lasting effects on nonmusical brain functions, such as language and attention, within individual lifetimes. Music is thus theorized to be a biologically powerful human invention, or “transformative technology of the mind.” </para>
    </section>
    <section id="id1164173304981">
      <title>1. Introduction</title>
      <para id="id1164181966934">The past decade has witnessed a rapid rise in cognitive and neuroscientific research on music. This has led to renewed interest in evolutionary questions about music, which originate with Darwin’s discussion of the topic in <emphasis effect="italics">The Descent of Man</emphasis> (1871). There are now several adaptationist theories arguing that musical behaviors originated via biological evolution due to their survival value for human ancestors. In contrast, nonadaptationist theories propose that musical behaviors are a human invention. The most prominent such theory, that of Steven Pinker (1997), regards music as a pleasure technology built from pre-existing brain functions (such as language, emotional vocalization, etc.), and posits, “As far as biological cause and effect are concerned, music is useless” (p. 528). </para>
      <para id="id1164172719127">Pinker’s idea that music is an invention built from existing brain functions provides a useful null hypothesis for evolutionary debates over music. His assertion that music is biologically useless, however, is problematic. While Pinker was likely referring to music’s impact on human biology over evolutionary time, as opposed to within the lifetime of individual humans, his writing does not make this distinction. Furthermore, the metaphors he uses to describe music (e.g., “auditory cheesecake,” or “recreational drugs”) imply a view of music as having little biological significance at either evolutionary or individual timescales.<footnote id="id4145261">While Pinker’s (1997) characterization of music as auditory cheesecake seemed to trivialize music, in more recent writings he has been more careful about assessing the value of music in human cultural life, noting, “The arts could be evolutionary by-products, and be among the most valuable human activities for all that” (Pinker, 2007, p. 170).</footnote></para>
      <para id="id3543008">A central point of this essay is that discussions of the biological significance of music should conceptually distinguish music’s effects over evolutionary time from its effects within individual lifetimes. The need for this distinction is driven by evidence from neuroscience. Neuroscientific research suggests that music is an invention that builds on diverse, pre-existing brain functions, rather than a trait that originated via processes of natural selection. This is consistent with Pinker’s thesis. However, growing evidence from neuroscience also suggests that music is biologically powerful, meaning that it can have lasting effects on nonmusical abilities (such as language or attention) during the lifetime of individual humans. Importantly, these effects can be observed not only in trained musicians but also in ordinary individuals who engage regularly with music. Thus, I believe that music should be regarded as a biologically powerful human invention or “transformative technology of the mind.” (For brevity, henceforth I refer to this idea as TTM theory.) </para>
      <para id="id1164169713641"> This essay is organized as follows. Section 2 introduces the evolutionary puzzle of music. Section 3 explains why neuroscience research suggests that music is an invention rather than a biological adaptation. Section 4 provides examples of the biological power of music. Section 5 suggests why music can have lasting effects on nonmusical brain functions. Section 6 provides a non-genetic explanation for why music is so pervasive in human culture. The essay concludes with a brief discussion of the relevance of a Darwinian perspective for the modern biological study of human music.</para>
      <para id="id1164175191470"> It is worth clarifying some points regarding TTM theory’s claim that music can shape brain function. It is obvious that engaging in any humanly-invented activity (e.g., kite flying) changes the brain within individual lifetimes, because learning and memory are instantiated by changes in neural networks, e.g., in the pattern of synaptic connections between neurons. Thus, TTM theory does not simply claim that musical behaviors change the brain. (This is trivially true: even learning a simple tune involves changing brain networks in some way in order to store the memory of the tune.) Nor does TTM theory simply claim that learning music results in lasting structural changes to the brain. (This claim would hardly be novel, given the growing evidence of experience-dependent changes in brain structure caused by learning a musical instrument, e.g., Hyde et al., 2009.) Rather, TTM theory claims that music is a human invention that can have lasting effects on such nonmusical brain functions as language, attention, and executive function, and is concerned with explaining the biological mechanisms underlying these effects.</para>
      <para id="id1164169410207">The qualification of “lasting” effects is important, because this distinguishes TTM theory from theories concerned with the short-term effects of music on other cognitive abilities (e.g., Thompson et al., 2001). That is, TTM theory is concerned with musically driven neurobiological changes that impact other brain functions over the course of months or years, not over the course of a few minutes. In this regard, TTM theory has some parallels to neurobiological theories of reading, another human invention with salient impact on the brain within individual lifetimes (Dehaene and Cohen, 2007). Indeed, reading can be considered another transformative technology of the mind, because it is a human invention built from existing brain systems (such as those supporting visuospatial cognition and language) that impacts a variety of mental abilities (Mar et al., 2008; Patel, 2008:400; Dehaene, 2009).</para>
      <para id="id1164183315823">Of course, music is much older and far more widespread than reading and appeals to humans from infancy. Also, unlike reading skills, basic musical abilities develop without any special instruction (Bigand and Poulin-Charronatt, 2006). These facts make the claim that music is a human invention seem odd. Yet other theories view ancient and universal human communication systems as inventions. For example, Tomasello (2008) has proposed that language originated as an invention based on communicative interactions between primates who had a special socio-cognitive ability for sharing actions and goals with others (“shared intentionality”; see also Lee et al., 2009). In common with such “language as invention” theories, TTM theory proposes that a complex and universal human trait can originate as an invention rather than as a biological adaptation. However, to my knowledge, all “language as invention” theories leave open the possibility that language, once invented, led to co-evolutionary changes in the brain that were aimed at supporting the acquisition of language (cf. Deacon, 1997). Indeed, the idea that our brains have been modified over evolutionary time to support the acquisition of language is favored by at least ten converging lines of evidence (Patel, 2008:358-366). TTM theory, in contrast, posits that there has been no evolutionary modification of our brains specifically aimed at facilitating musical abilities. Instead, music is viewed as a technology that is learned anew by each new generation of human minds. This view is congenial to the tremendous diversity of musical practices that have been described by ethnomusicologists (e.g., Titon, 1996; Nettl and Stone, 1998) and to the seemingly endless growth and development of music as a human art form (Ross, 2007). It is important to note, however, that TTM theory does not amount to the claim that humans are musical blank slates. Since music is theorized as building on preexisting brain functions (such as language and auditory scene analysis<footnote id="id1164169247536">The process by which the human auditory system organizes sound into perceptually meaningful elements or sources (Bregman, 1990).</footnote>), processing predispositions relevant to these other functions are likely to be reflected in the structure and processing of human music (cf. Reynolds, 2005; Dehaene and Cohen, 2007).</para>
      <para id="id1164169391500">A final conceptual point about TTM theory  concerning the fundamental question of why humans are drawn to musical behaviors merits discussion here. TTM theory claims that music can have lasting effects on nonmusical brain systems, but it does not propose that humans engage in music in order to produce these effects. Rather, as discussed in section 6 below, TTM theory posits that people are drawn to music because of its emotional power and because of its efficacy for ritual and memory. The lasting effects on nonmusical abilities are thus a <emphasis effect="italics">consequence</emphasis> of how music engages the brain, not a <emphasis effect="italics">cause</emphasis> of musical behavior. A better understanding of how and why these effects occur is of interest both for basic brain science and for designing musical activities to address problems in nonmusical domains, i.e., in scientifically-based music therapy (Leins et al., 2009).</para>
    </section>
    <section id="id1164169717106">
      <title>2. The evolutionary puzzle of music</title>
      <para id="id5771738">Like language, music is a human universal that reaches deep into our species’ past (Nettl, 2000). Recent excavations have revealed bone flutes dating to the late Pleistocene era (~40,000 ybp, Conard et al., 2009). Cross-cultural and developmental research indicates that listening to and/or making music has a profound appeal to most members of our species, starting early in life (Blacking, 1973; Trehub, 2003). Thus, one can predict with some confidence that the few remaining uncontacted tribes of humans, when finally described by anthropologists, will have music as part of their behavioral repertoire.</para>
      <para id="id1164169286959"> For those interested in the evolutionary foundations of human behavior, such observations are puzzling. Musical activities lack any obvious survival value. Why then is music so pervasive in human life? Are we musical today because music helped our ancestors survive? Has the human mind been shaped by natural selection for music? Darwin (1871) was the first to wrestle with these questions, noting that “as neither the enjoyment nor the capacity of producing musical notes are faculties of the least direct use to man in reference to his ordinary habits of life, they must be ranked among the most mysterious with which he is endowed” (p. 1207). </para>
      <para id="id1164170646210">In <emphasis effect="italics">The Descent of Man</emphasis>, Darwin offered an adaptationist theory of music’s origins based on principles of sexual selection (see Kivy, 1959, for a discussion of these ideas in a larger historical framework). For the next century, scholarly discussion of music and evolution was relatively sparse but began to stir again with the rise of cognitive studies of music (e.g., Roederer, 1984). Interest in the topic has grown considerably in the past decade, reflecting the explosion of cognitive neuroscience research on music (Peretz, 2006). Indeed, since 2000, two scientific volumes of essays have been devoted to the evolution of music (Wallin et al., 2000; Vitouch and Ladinig, 2009), and the topic has been addressed in many other books and scholarly articles (e.g., Pinker 1997; Hauser and McDermott, 2003; Mithen 2005; Fitch, 2006, 2010; Hagen and Hammerstein, 2009; Kirschner and Tomasello, in press). Several adaptationist and nonadaptationist proposals are now in existence; some of the more prominent ones are reviewed below.</para>
      <section id="id1164174773587">
        <title>2.1 Adaptationist proposals</title>
        <para id="id1164169900494">The first evolutionary theory for music was offered by Darwin in <emphasis effect="italics">The Descent of Man</emphasis> (1871). Darwin drew an analogy with birdsong and theorized that music arose in our ancestors via mechanisms of sexual selection. He wrote: “Musical tones and rhythm were used by the half-human progenitors of man, during the season of courtship, when animals of all kinds are excited by the strongest passions” (p. 1209). Darwin speculated that wordless courtship songs predated our linguistic abilities and that such singing provided the scaffolding upon which language itself evolved. This idea of a musical protolanguage has proved of enduring interest to scholars researching the evolution of language and music (e.g., Brown, 2000(a); Mithen, 2005; see Fitch, 2010, for an overview and a recent version of the musical protolanguage theory). Indeed, the idea of a shared origin for language and music is pre-Darwinian, dating at least as far back as French enlightenment writings in the 1700s (Thomas, 1995). Commencing with Darwin, however, scholars have explored the idea within an evolutionary framework, proposing theories for how such a form of communication could have evolved and seeking to explain how it could further evolve into articulate language and fully developed music. Such theories view music as having a biological rather than a purely cultural origin and posit that musical behaviors had survival value for our ancestors. </para>
        <para id="id1164171006745"> This section focuses on the three most prominent adaptationist theories of music, based on sexual selection, parental care, and group cohesion. These theories have been proposed and explored independently but are not mutually exclusive. Indeed, musical protolanguage theories often invoke all three such theories to account for the biological origin of musical behavior.</para>
        <para id="id1164169619476">As noted above, the sexual selection theory of music originated with Darwin. Sexual selection has the appeal of being able to explain the evolution of elaborate traits that seem nonadapative, or even maladaptive, in the daily struggle for existence, yet that are beneficial in the competition for mates (the peacock’s tail is a classic example). The sexual selection theory of human music has been explored by Miller (2000) and others and continues to attract interest. </para>
        <para id="id3541876"> A second set of adaptationist proposals concerns parental care rather than sexual selection. As often noted by biologists, human infants are born remarkably early in their biological development compared to other primates, possibly due to constraints on the size of the birth canal imposed by bipedalism (Mithen, 2005). Dissanayake (2008) and Falk (2004) have pointed to the cross-cultural importance of vocal communication in human infant care, whereby adults use melodious and rhythmic affect-laden utterances (“motherese”) to soothe or arouse prelinguistic infants. Positing that such vocalizations had adaptive value for infant survival, these authors propose that music has its origins in vocalizations aimed at caring for infant offspring.</para>
        <para id="id1164170262102">A third set of adaptationist proposals concerns possible benefits of music to group cohesion. Humans, like most other primates, live in groups where individual competition is balanced with cooperation. Humans are unusual, however, in having relatively low degrees of in-group genetic relatedness (due to high gene flow between groups), yet depending to a large degree on in-group cooperation in order to survive and outcompete other groups (Richerson and Boyd, 2005). There has been much recent interest in the idea that music may have served as a mechanism to promote social cohesion within groups (e.g., Brown, 2000(b)). This idea was first clearly articulated by Roederer (1984), who pointed to “the value of music as a means of transmitting information on emotional states and its effect in congregating and behaviorally equalizing masses of people.” Dunbar (in press) has argued that group singing and dancing replaced physical grooming in ancestral human groups, when increasing group size made physical grooming of allies impractical. According to this view, song and dance led to endorphin release (mimicking the neural effects of physical grooming). This in turn promoted bonding, because endorphins, “as a byproduct of their role in pain control…have the property of making us feel warm and well disposed towards others who share…the experience that stimulates their production” (cf. Cohen et al., 2009, Kosfeld et al., 2005).</para>
        <para id="id1164170765716">One appeal of the social cohesion idea is that music is often a social activity among humans, especially in small-scale cultures, and experimental work suggests that musical group activities promote cooperation between group members on subsequent nonmusical tasks (e.g., Wiltermuth and Heath, 2009; Kirschner and Tomasello, in press). Furthermore, music has certain design features that distinguish it from language, such as discrete pitches (allowing voices to blend together in song) and a distinct beat (enabling synchronized movement through time), which facilitate coordination between individuals and can promote a shared sense of identity and purpose (McNeill, 1995; Bispham, 2006).</para>
        <para id="id1164179847604"> Social cohesion hypotheses are currently a focus of much interest within music cognition, mirroring a growing interest within biology in natural selection at the level of social groups (e.g., Wilson and Wilson, 2007; Wilson et al., 2008). Several variant hypotheses have developed. Cross (2009), for example, draws on ethnomusicological literature and emphasizes music’s efficacy in managing situations of social uncertainty, i.e., situations in which linguistic interaction might give rise to conflict. He also emphasizes the role of music as a training ground for social cognition (cf. Boyd, 2009). Merker (2000), in contrast, draws on observations of chimpanzee group vocal displays and theorizes that music may have originated in our ancestors from synchronous calls aimed at mate attraction (see also Merker et al., 2009). Hagen and Hammerstein (2009) draw on comparative data from nonhuman primates and carnivorous mammals thought to be ecologically similar to human ancestors, and suggest that music may have arisen from group vocal territorial advertisements (for antecedents of this idea, see Geissmann, 2000). </para>
        <para id="id1164169786165">Another version of the social cohesion hypothesis is notable for the relatively small degree of biological specialization for music that it proposes (Kirschner and Tomasello, in press). According to this view, music originated as an invention in ancestral human groups. Because music promoted group cohesion and survival, it acted as a cultural (vs. biological) adaptation, so that musically-oriented groups outsurvived other groups. Subsequently, due to feedback between cultural group selection and biological natural selection, there was selection for individuals who were biologically predisposed toward musical behavior.<footnote id="id8831656">See Richerson and Boyd, 2005, Ch. 6, for a general discussion of gene-culture coevolution in the context of human cooperative behavior.</footnote> Thus, according to Kirschner and Tomasello, modern humans are hypothesized to have “an innate proclivity for musical sounds and actions” without necessarily having any other brain specializations for music processing (cf. Trehub and Hannon, 2006).<footnote id="id1164173738903">The foregoing discussion of several adaptationist theories is necessarily brief, and readers desiring a wider and deeper discussion of adaptationist ideas are referred to the primary literature cited above.</footnote></para>
        <para id="id1164170684046"> For the sake of brevity, a critique of the above theories is not provided here (the interested reader is referred to Patel, 2008: 368-371). For the current purposes, the relevant point is that all despite their different points of emphasis, all adaptationist proposals view the human mind as having been specifically shaped by evolution to support musical behavior.</para>
      </section>
      <section id="id1164178734090">
        <title>2.2 Nonadaptationist proposals</title>
        <para id="id6881494">In sharp contrast to adaptationist theories, nonadaptationist theories of music posit that there has been no natural selection for musical abilities in our species. Herbert Spencer implicitly took this position (even prior to the publication of Darwin’s <emphasis effect="italics">Origin of Species</emphasis>) in his essay, “On the origin and function of music” (Spencer, 1857). Spencer argued that music grew out of the rhythms and cadences of impassioned speech and launched a debate that engaged Darwin and many other scholars (for a fascinating discussion, see Kivy, 1960, 1964, and Rehding, 2000). </para>
        <para id="id1164171539907">Some thirty years later, William James voiced a nonadaptationist view of music in <emphasis effect="italics">The Principles of Psychology</emphasis> (1890). James regarded the human love of music as “a mere incidental peculiarity of the nervous system” (Vol. 2, p. 419) and asserted: “It has no zoological utility…it is a pure <emphasis effect="italics">incident </emphasis>of having a hearing organ…it has entered the mind by the back stairs, as it were, or rather [has] not entered the mind at all, but got surreptitiously born in the house” (Vol. 2, p. 627).</para>
        <para id="id1164170579864">A modern descendant of James’ view is that of Pinker (1997: 528-538), which has become the most prominent nonadaptationist theory of music. Pinker’s proposal starts with the theory that many human mental faculties have been direct targets of natural selection. Music is chosen as a counterexample and is argued to be a human invention that is universal because of its link to pleasure: “Music appears to be a pure pleasure technology, a cocktail of recreational drugs that we ingest through the ear to stimulate a mass of pleasure circuits at once” (p. 528). In a later essay, Pinker (2007) elaborates this point to propose that music and many other human arts are “by-products of two other traits: motivational systems that give us pleasure when we experience signals that correlate with adaptive outcomes…and the technological know-how to create purified doses of these signals…” (p. 171).</para>
        <para id="id1164178943210"> Pinker’s proposal is notable for its specificity in suggesting the nonmusical foundations upon which music builds. These are: 1) the prosodic component of language, 2) auditory scene analysis, 3) emotional calls, 4) habitat selection, and 5) motor control.<footnote id="id1164173721790">Pinker also allows for the possibility that the love of music is a chance byproduct of the wiring of our brains, e.g., “some kind of…short-circuit or coupling that came along as an accident of the way that auditory, emotional, language, and motor circuits are packed together in the brain” (p. 538). </footnote> According to Pinker, music brings us pleasure because it “tickles the sensitive spots” of these faculties. Specifically, 1) music has prosody-like properties, and the brain rewards the analysis of prosodic signals (patterns of linguistic rhythm and intonation) because prosody is an important component of language; 2) music is rich in harmonic sounds (sounds in which frequency components are integer multiples of some fundamental frequency), and the brain rewards the analysis of such sounds because harmonicity is an acoustic cue used to identify sound sources, an important part of auditory scene analysis; 3) music can evoke strong emotions because it contains pitch and rhythm patterns that resemble our species’ emotional calls, and 4) because it contains sound patterns reminiscent of evocative environmental sounds (e.g. “safe” or “unsafe” sounds, such as thunder, wind, or growls); 5) musical rhythm engenders rhythmic movement (e.g., in dance), and such movement is rewarded by the brain because rhythmic motor patterns are associated with biologically meaningful behaviors, such as walking, running, or digging. </para>
        <para id="id1164169801953"> Pinker’s proposal is much more detailed than that of James (1890), informed as it is by the century of cognitive science research that separates the two books. (For example, Pinker discusses in detail the influential music-cognition theories of Lerdahl and Jackendoff, 1983.) Nevertheless, James and Pinker arrive at a similar view of the biological significance of music. James wrote that music has “no zoological utility,” and Pinker asserts, “As far as biological cause and effect are concerned, music is useless.” Perhaps James and Pinker were referring to evolutionary utility as opposed to utility during the lifetime of individual humans, but their writings do not specify this. Furthermore, Pinker’s metaphor of music as a recreational drug implies a view of music as having a rather superficial relationship to human biology. </para>
        <para id="id1164169433343">There are now several nonadaptationist theories of music, each offering distinct hypotheses about the brain systems upon which music builds. Livingstone and Thompson (2009), for example, argue that music builds on a recently evolved human theory of mind ability to serve the primary purpose of affective engagement. Panksepp (2009), in contrast, emphasizes music’s connection to evolutionarily ancient socio-emotional brain circuitry. There are other nonadaptationist proposals (e.g., Sperber, 1996), but none systematically considers music’s power to shape human brain function. It is on this point that TTM theory differs from existing nonadaptationist theories of music.</para>
      </section>
    </section>
    <section id="id1164186439878">
      <title>3. Music as a human invention</title>
      <para id="id1164169405697">Given the debates over the evolutionary status of music, it is parsimonious to adopt the null hypothesis that there has been no natural selection for musical abilities in our species and then ask if there is enough evidence to seriously challenge this null hypothesis. When this strategy is applied to language, there appears to be enough evidence to refute the null hypothesis, as reviewed in Patel (2008: 358-366). </para>
      <para id="id1164173616210"> What of music? To some, the universal and ancient nature of human music may imply that it originated as a biological adaptation. The danger of such an assumption is illustrated by another remarkable human trait, namely the control of fire. This trait extends deep into our species’ past and is found in every human culture, yet few would dispute that it arose as an invention rather than a biological adaptation. The universality of the trait can be explained by the fact that it provides things that are universally valued by humans, including the ability to cook food, keep warm, and see in dark places. The example of fire-making teaches us that when we see a universal and ancient human trait, we cannot simply assume that it has been a direct target of natural selection (Patel, 2008: 356).<footnote id="id8138524">Wrangham (2009) has argued persuasively that the control of fire and the invention of cooking by human ancestors led to co-evolutionary changes in physiology, such that modern humans are now biologically adapted to eating cooked food.  He argues that cooking makes certain animal proteins more digestible and softens food, which reduces the cost of digestion. Consequently, our gut shrank over evolutionary time, allowing valuable metabolic energy to be diverted to our brains, which could then grow larger, since brains are energetically very expensive.  The idea of a human invention leading to co-evolutionary changes in body and brain is an interesting one, though TTM theory does not take this approach when considering the biological impact of music.</footnote></para>
      <para id="id1164170294909">It is tempting to think that brain specialization for certain aspects of music cognition (Peretz, 2006) and the existence of genetically-based deficits of music perception (Drayna et al. 2001; Peretz et al., 2007) point to natural selection for music. Yet upon closer examination, these facts provide no compelling support for adaptationist theories. Here, reading and writing provide useful analogies. These are indisputably human inventions, probably no more than about six thousand years old, making them too young to be associated with any evolutionary brain specialization for these abilities. Yet brain imaging studies of literate individuals have shown that certain aspects of reading, e.g., recognizing written characters, are associated with functional specializations in specific brain regions (Dehaene and Cohen, 2007; cf. Stewart et al., 2003). This specialization is clearly a product of experience-dependent neural plasticity, i.e., long-lasting changes in neurons and brain networks driven by experiences within an individual lifetime (Dehaene, 2009). Furthermore, certain reading disorders have a genetic component (Fisher and Franks, 2006), even though one can be confident that humans have not undergone natural selection for reading abilities. That is, specific genes can influence brain circuits that happen to be important for a complex human ability without any implication of natural selection for that ability. </para>
      <para id="id1164183237478">The examples of fire-making and reading show that the evolutionary null hypothesis for music is not challenged by music’s universality, age, association with some degree of brain specialization, or its influence by specific genes. Challenges to the null hypothesis thus must come from other sources. Patel (2008: 367-400) reviewed a wide range of evidence in this regard, including data from neuroscience, infant studies, and animal studies, and argued that at present the null hypothesis for music could not be rejected. </para>
      <para id="id1164173518645">Rather than rehearse those arguments here, sections 3.1 and 3.2 below take a different approach and illustrate two lines of research that support the idea of music as an invention. These studies illustrate a comparative approach to the evolutionary biology of music (McDermott and Hauser, 2003; Justus and Hutsler, 2005). The basic logic of this approach is as follows: If one can show that an aspect of music cognition is rooted in other, nonmusical human brain functions or is shared with other species, then it is parsimonious to assume that this aspect has not been shaped by natural selection for music. This approach is particularly powerful when applied to aspects of music which seem domain-specific, i.e., not related to other types of cognition, such as tonality processing and synchronization of movement to a musical beat (Peretz and Coltheart, 2003; Bispham, 2006). </para>
      <section id="id1164174299110">
        <title>3.1 Tonality processing: connections to language</title>
        <para id="id1164169826412">Most of the world’s musical systems use discrete pitches and intervals to create melodies, with the pitches drawn from musical scales of five to seven tones per octave (Reck, 1997). A widespread feature of music is the <emphasis effect="italics">differential</emphasis> use of scale pitches such that some are perceived as more stable or structurally significant than others (Krumhansl, 1990). This differentiation of scale pitches in terms of stability or prominence has been termed a “tonal hierarchy,” and implicit knowledge of such hierarchies develops without any special musical training (Tillmann et al., 2000). This knowledge contributes to our subjective impressions that tones in a musical context have abstract perceptual properties, such as tension or resolution, that are distinct from standard psychophysical tone properties such as “higher or lower” or “louder or softer.”</para>
        <para id="id1164170917689">Krumhansl and Cuddy (in press) argue that “tonal hierarchies…play a central role in how musical sequences are perceived, organized, remembered, and how expectations are formed during listening.” Furthermore, they note that this way of organizing pitch is unique to music, an assertion supported by the fact that language, which can use pitch in highly structured ways, has nothing resembling tonality (cf. Patel, 2008, Ch. 2). Indeed, Peretz and Coltheart (2003) have proposed that processing of tonality in music uses domain-specific brain mechanisms. This view is supported by neurological cases in which brain damage selectively impairs tonality processing while leaving more basic forms of auditory processing, as well as language processing, intact (e.g., Peretz, 1993).</para>
        <para id="id1164171072120">Neuroimaging of healthy individuals has challenged a domain-specific view of tonality processing, however. This challenge commenced with a study that directly compared brainwave (“event-related potential,” or ERP) activity associated with syntactic processing of language and tonal-harmonic processing of music and found a surprising degree of overlap (Patel et al., 1998). Subsequently, neuroimaging studies using a variety of techniques (e.g., MEG, fMRI) have suggested overlap in brain areas involved in linguistic syntactic processing and musical tonal-harmonic processing (e.g., Maess et al., 2001; Koelsch et al., 2002; Tillmann et al., 2003; Patel, in press(b)). The apparent paradox between data from neurological patients (which support a domain-specific view of tonality) and from neuroimaging (which support a non domain-specific view) led to the “shared syntactic integration resource hypothesis” or SSIRH (Patel, 2003). The SSIRH posits that language and music rely on domain-specific structural knowledge stored in long-term memory (e.g., knowledge of words and their syntactic features or chords and their harmonic relations), but that integration of words or musical tones into hierarchical structures during auditory processing relies on shared, limited neural resources (see Patel, in press (a), for further details and Patel, 2008, Ch. 5, for a full treatment). The SSIRH posits that cases of neurological dissociation result from damage to domain-specific representations, while the similar brain responses seen in neuroimaging studies of healthy individuals reflect shared processes of structural integration operating on these domain-specific representations. Crucially, the SSIRH makes testable predictions, including the prediction that simultaneous structural integration demands in language and music should lead to processing interference. To date, these predictions have been supported by both behavioral and neural studies (Koelsch et al., 2005; Steinbeis and Koelsch, 2008; Fedorenko et al., 2009; Slevc et al., 2009).</para>
        <para id="id8853508"> Recently, further evidence for overlap between linguistic syntactic processing and musical tonality processing has emerged from clinical studies, including neuroimaging research on specific language impairment (Jentschke et al., 2008), intracranial EEG studies of epileptic patients (Sammler, 2009), and behavioral studies of agrammatic Broca’s aphasia (Patel et al., 2008).<footnote id="id1164170903313">The studies of music perception in aphasia have focused on patients with left hemisphere brain damage and “agrammatic comprehension,” i.e., difficulty understanding the meanings of sentences based on their grammatical structure, rather than difficulty understanding the meanings of individual words. For example, such patients, if told the sentence “The girl on the chair was greeted by the man,” would understand that the sentence referred to a girl, a chair, a man, and an act of greeting, but would be unsure of who did what to whom. See Patel et al., 2008, for further discussion. </footnote> Given this growing evidence for links between tonality processing and linguistic syntactic processing, it is worth stepping back and asking why such connections should exist. After all, instrumental music and linguistic sentences serve different communicative ends and are built from distinct raw materials (e.g., musical tones vs. syllables). Furthermore, the hierarchical structures that organize tones vs. words have been argued to be quite different (Jackendoff, 2009, though see Rohrmeier, 2007, for a different view). Why then would the processing of structural relations in music and language engage similar brain mechanisms?</para>
        <para id="id1164173594735"> A notable similarity between tonality and linguistic syntax is the existence of abstract structural categories that organize sequences of events. In tonality, for example, structural categories such as the tonic (the most stable pitch in the tonal hierarchy) or leading tone (an unstable pitch in the hierarchy) can be realized by any pitch. For example, the pitch B4 (493.9 Hz) can serve as either the tonic or leading tone of a melody, depending on prevailing tonal hierarchy. Language also has abstract structural categories, such as grammatical subject and object, that can be realized by a variety of words. </para>
        <para id="id1164179839351">In both domains, abstract categories play an important role in mental processes involved in sequence comprehension. To take one example, in processing a melody one may expect a tonic as the next note (vs. expecting a specific tone frequency in Hz), and in processing language, it is possible to expect a grammatical object as the next word (vs. expecting a particular word) (Huron, 2006; Gibson, 2006). To take another example, in both domains incoming categories vary in how easy they are to integrate into the existing structural representation of the sequence (Bigand et al., 2003; Koelsch et al., 2007; Gibson, 1998; Levy, 2008). According to the SSIRH, difficult structural integrations in both domains draw on a shared pool of limited neural resources (see Patel, in press (a), for details).</para>
        <para id="id1164171343275"> To recap, tonality involves domain-specific <emphasis effect="italics">knowledge</emphasis>: the long-term knowledge of tonal hierarchies, for example, is specific to music. Yet online processing of tonal relations appears to share mechanisms with language processing, possibly because tonality, like linguistic syntax, deals in abstract categories that are processed in terms of hierarchical structures. The deeper lesson, in terms of exploring links between music cognition and other domains, is the importance of distinguishing domain-specific representations from non-domain-specific processing mechanisms. Indeed, in the case of tonality, non domain-specific mechanisms may be important not only for online processing, but also for the acquisition of knowledge. According to Krumhansl and Cuddy (in press), two psychological principles underlie the development of tonal hierarchies in the mind of a listener: the use of cognitive “reference points” and mechanisms of statistical learning. They note that neither principle is unique to music, but that the application of these principles to music results in domain-specific musical knowledge. In other words, tonal music may represent a case of the mind creating domain-specific knowledge via non domain-specific processes (cf. McMullen and Saffran, 2004).</para>
        <para id="id1164175443737"/>
      </section>
      <section id="id1164182118249">
        <title>3.2 Entrainment to a musical beat: connections to vocal learning</title>
        <para id="id1164170985596">In every human culture there is some form of music with a periodic beat pattern, to which people synchronize their rhythmic movements, e.g., in dance (Nettl, 2000).<footnote id="id1164169857882">Periodic beat patterns need not be based on an isochronous (metronomic)
pulse. For example, Balkan rhythms can have temporally-repeating cycles of
beats, with each cycle having asymmetric time intervals between beats (cf.
Patel, 2008: 98).</footnote> Musical beat perception and synchronization (BPS) is an example of the entrainment of rhythmic action to rhythmic sound. BPS does not appear to be an offshoot of language. Language has rich rhythmic structure and can involve tight temporal coordination (e.g., in conversational turn-taking), but does not have temporally periodic beats and does not elicit periodic rhythmic movement from listeners (Patel, 2008, Ch. 3). Notably, BPS (e.g., head bobbing and foot tapping to music) emerges without any special instruction in humans, which makes it an intriguing topic of study from the standpoint of evolutionary biology. Has the human brain been specifically shaped to support this ability? </para>
        <para id="id1164173355814">This question is particularly salient since BPS is distinct in a number of ways from other examples of animal entrainment in nature, e.g. the synchronous chirping of katydids (Greenfield and Schul, 2008). For example, human synchronization to music is very flexible in terms of tempo, is a response to complex sound sequences (not just pulse trains), and is truly cross-modal since it often involves silent rhythmic movement in response to sound. No other species combines these features in their natural entrainment behavior (Patel et al., 2009a). Furthermore, familiar domestic animals such as dogs and cats show no tendency for spontaneous rhythmic movement to music, even though they have lived with humans and their music for thousands of years. Indeed, BPS has been proposed to be a uniquely human ability (Bispham, 2006), reflecting natural selection for musical behavior in our species, perhaps in the service of promoting group cohesion (cf. Dunbar, in press and section 2.1 above).</para>
        <para id="id1164170759673">Yet neurobiology suggests that BPS may have hidden connections to brain systems with other “day jobs.” Specifically, BPS may build on the brain circuitry for complex vocal learning, a trait shared by humans and only a few other groups of mammals and birds. Vocal learning is associated with specific evolutionary modifications to the brain (Jarvis, 2009) and, like BPS, involves a high degree of neural integration between the auditory and motor systems (Patel et al., 2005). The “vocal learning and rhythmic synchronization hypothesis” (Patel, 2006) posits that vocal learning provides a neurobiological foundation for BPS. One prediction of this hypothesis is that non-vocal-learning species, which includes all non-human primates, are incapable of BPS. While direct tests of this prediction are still needed via training studies involving movement to music, some support is provided by a recent study that attempted to teach rhesus macaques to synchronize their finger movements to a metronome (Zarco et al., 2009). Despite more than a year of concerted training (six days/week, four hours/day), the monkeys were unable to learn to align their taps in time with the metronome signal—a task that is easy for humans, even young children with no musical training (McAuley et al., 2006). </para>
        <para id="id6545710">Additional support for the vocal learning hypothesis has recently been provided by the discovery of entrainment to human music in several parrot species (Patel et al., 2009b, Schachner et al., 2009). Tempo flexibility was demonstrated in an experiment with a sulphur-crested cockatoo (<emphasis effect="italics">Cacatua galerita eleonora</emphasis>), in which the tempo of a song was manipulated to create different versions ranging from twenty percent slower to twenty percent faster than the original song. The animal was able to synchronize its head bobs to the beat of the music at several different tempi. Synchronization occurred in “bouts,” or periods of sustained entrainment, interspersed in longer episodes of dancing not synchronized to the beat. Interestingly, the non-synchronized dancing was dominated by a preferred tempo of rhythmic movement, and synchronization was best when the musical tempo was near this preferred tempo (Patel et al., 2009c), patterns that have also been observed in how human children move to music (Eerola et al., 2006). Thus, it appears that parrots may resemble human children (vs. adults) in terms of how they move to rhythmic music, though further research is needed to test this idea.</para>
        <para id="id1164170395140">Crucially, parrots (as far as is known) do not entrain rhythmic movements to rhythmic sounds as part of their natural behavior, indicating that BPS does not require a brain that has been shaped by natural selection for this ability. Furthermore, modern neuroanatomical research suggests that vocal learning in birds and mammals uses homologous brain circuits involving the thalamus, striatum, and forebrain, despite the fact that the mammalian and avian lineages diverged over 200 million years ago (Jarvis, 2007). In other words, there seem to be genetic and neural constraints on how vocal learning is acquired in vertebrate brains, so that even when the ability arises in distantly related vertebrate groups, similar underlying brain mechanisms are at play. This idea of “deep homology” underlying vocal learning circuitry in birds and humans suggests that a brain shaped by evolution for vocal learning has “BPS potential” as a byproduct of its wiring (see Patel et al., 2009a, for further discussion). </para>
      </section>
      <section id="id8091916">
        <title>3.3 Music as a human invention: summary</title>
        <para id="id1164170666510">The above sections indicate that two core components of music cognition—tonality processing and entrainment to a musical beat—have strong relationships to nonmusical brain functions. Notably, while these aspects seem domain-specific to music at first glance, research grounded in neuroscience points to their underlying connections to nonmusical brain functions. Thus, these aspects of music cognition can be explained without invoking evolutionary brain specialization for music, which is consistent with the idea that music is an invention.</para>
        <para id="id1164170646810">If music is an invention, then future research will show that every component of music cognition can either be related to a nonmusical brain function or be explained via learning in the absence of any evolutionary specialization for music. Of course, even if this is shown to be the case, music cognition as a whole will still be special because it creates a unique confluence of different processing components in the human mind. It is interesting to speculate that the nature of this confluence may vary in interesting ways across cultures and historical epochs, depending on which processing components a culture uses in building its musical system.</para>
      </section>
    </section>
    <section id="id1164170646814">
      <title>4. The biological power of music: two examples</title>
      <para id="id1164170801083">Challenges to the most prominent nonadaptationist theory of music (Pinker, 1997), which views music as a “biologically useless” invention, come from studies showing that regular engagement with music can result in lasting changes to nonmusical brain functions. Importantly, such studies concern individuals who are not professional musicians. There has been a good deal of research on structural brain differences between professional musicians and non-musicians (e.g., Elbert et al., 1995; Schneider et al., 2002; Bengtsson et al., 2005; Stewart, 2008), with recent research supporting the idea that many such differences can be explained by experience-dependent neural plasticity (e.g., Hyde et al., 2009; Schlaug, Forgeard et al., 2009). The current focus, however, is on evidence that regular engagement with music can exert lasting effects on brain functions in a wider range of individuals (e.g., Sacks, 2007; Dalla Bella et al., 2009; Bradt et al., in press). </para>
      <para id="id5097492">Before discussing neurological studies, it is worth saying a few words about the effect of regular music lessons on the cognitive abilities of children, a topic of great public interest. This issue has been explored experimentally by Schellenberg (2004). He conducted a study in which six-year-old first-graders were randomly assigned to weekly keyboard lessons, voice lessons, drama lessons, or no lessons for one year. Each child was tested twice on a standardized intelligence test: once before entering first grade, and once in the summer after first grade. This test had twelve subtests measuring a variety of nonmusical cognitive skills. Children in all groups showed IQ increases over time, as expected due to attending first grade, but those receiving music lessons gained significantly more IQ points than those taking drama or no lessons.<footnote id="id1164171240288">The drama group, in contrast, outgained other groups in social skills, such as cooperating with peers. For further research on the possible cognitive benefits of drama training, see Goldstein et al., 2009-2010.</footnote> Based on the fact that the IQ gains in the music groups were seen across a majority of the twelve subtests, Schellenberg argued that music training influences a variety of non-domain-specific skills (e.g., memorization, fine motor skills) or general mental processes relevant to many different cognitive tasks, such as executive function (the ability to organize mental tasks, control impulses, etc.) and abstract reasoning (see Schellenberg, 2006, for further details).<footnote id="id1164170127783">Schellenberg (2006) is also recommended for its extensive discussion of the controversial “Mozart effect,” whereby passive music listening has short-lived effects on certain nonmusical cognitive tasks.</footnote> Schellenberg’s findings support the view that regular engagement with music influences a variety of nonmusical brain functions. </para>
      <section id="id8812899">
        <title>4.1 Music and the recovery of brain functions after stroke</title>
        <para id="id1164169244410">A recent study by Särkämö and colleagues (2008) provides evidence that regular listening to music can aid in the recovery of brain functions following stroke. These authors studied 60 patients with left or right hemisphere middle cerebral artery stroke,<footnote id="id6912461">Acute ischaemic MCA stroke in the left or right temporal, frontal, parietal, or subcortical brain regions, with no prior neurological or psychiatric diseases (mean participant age: 56 years).</footnote> who were randomly assigned to one of three groups. A music group listened to one hour of self-selected music per day, a story group listened to one hour of self-selected stories per day, and a control group had no additional treatment. (All three groups received standard stroke therapy.) Music therapists assisted in providing portable audio players and audio materials and in encouraging patients to listen. The experimental interventions lasted for two months, beginning soon after stroke onset. All of the patients were assessed on seven nonmusical cognitive tasks and eight mood measures, once soon after stroke onset and then again at three and six months post-stroke. The cognitive tasks examined verbal memory, short-term memory, language, visuospatial cognition, focused attention, sustained attention, and executive functions. The mood measures examined tension, depression, irritability, vigor, fatigue, inertia, confusion, and forgetfulness. All tests were administered by people unaware of which group the patients were a part.</para>
        <para id="id1164170476784"> The three groups showed no significant differences in any measures soon after stroke onset. However, at three and/or six months, significant differences emerged between groups on two cognitive tests and two mood measures. On the cognitive tests, verbal memory and focused attention were superior in the music group compared to the other two groups. On the mood measures, the music group showed significantly less depression and confusion than the control group. For other cognitive and mood measures, the groups showed comparable performance at three and six months, and in no case did the music group perform worse than the other groups.</para>
        <para id="id1164170761620">These findings are striking because they suggest lasting positive effects of passive music listening on neural recovery after stroke. What physiological mechanisms might underlie these effects? Prior research with healthy individuals indicates that pleasurable music listening is associated with activation of reward areas of the brain (e.g., the ventral tegmental area) that project dopamine to wide regions of the cerebral cortex (Menon and Levitin, 2005). The authors thus speculate that the activation of the dopaminergic mesocorticolimbic system by music may have led to enhanced general arousal and mood and suggest that this in turn influenced performance on cognitive tasks. In support of this idea, they point to prior research with healthy individuals that finds links between music-induced positive arousal/mood and performance on nonmusical cognitive tasks (e.g., Thompson et al., 2001). </para>
        <para id="id1164171188206">Two problems with this account, however, are that the prior research was concerned with <emphasis effect="italics">transient</emphasis> effects of music on immediately administered cognitive tasks (i.e., effects lasting minutes, not days or weeks), and that the dopamine-arousal hypothesis cannot explain why the music group showed improvement on only the verbal memory and focused attention cognitive tasks. It is interesting to consider the possible role of hormones in the current findings because of their long-lasting effects on brain physiology. For example, the glucocorticoid hormone cortisol is secreted by the adrenal glands in response to stress, as a result of neuroendocrine signals from the brain. A major stroke is a life-changing event that seems likely to result in greatly elevated stress in the months following the stroke, due to loss of one’s normal physical and mental abilities. This may in turn result in chronically elevated cortisol levels. Sustained high cortisol levels have deleterious structural effects on neurons in the hippocampus, a brain region rich in glucocorticoid receptors (Sapolsky, 2000) and involved in verbal memory in older adults (Zimmerman et al., 2008).</para>
        <para id="id1164176677388">How does music enter this picture? Cortisol production is regulated by signals from the hypothalamus, a brain structure that is influenced by projections from the limbic system (brain structures involved in regulating emotion). The limbic system in turn is influenced by music (Peretz, 2010; Koelsch, 2010). The mechanisms underlying this influence remain unclear and may involve sensitivity of the limbic system to voice-like acoustic cues to affect, cues that occur in exaggerated form in music (cf. Juslin and Laukka, 2003). Interestingly, experiments with healthy individuals show that music listening immediately after a stressful event transiently reduces cortisol levels (Khalfa et al., 2003). Thus, one can hypothesize that regular music listening after stroke helps lower average cortisol levels, and these reduced levels facilitate hippocampal function. This could help account for the superior verbal memory of the stroke patients in the music-listening group. The superior performance of this group on sustained attention tasks remains to be explained, however. Neuroimaging research has shown that attentive listening to music recruits domain-general attentional networks (Janata et al., 2002), but it is not clear why or how regular activation of these networks by music would facilitate their operation during nonmusical tasks.</para>
        <para id="id1164170818896">Humans are deeply social creatures, and thus one important question concerns possible increased benefits of social musical activities on cognitive and emotional function after stroke. That is, active engagement of patients in singing or playing instruments may have greater cognitive, emotional, and motor benefits on neural recovery than passive listening to music. In particular, it would be worth comparing live therapy vs. passive listening in terms of the cognitive and mood measures applied by Särkämö et al. If live therapy is substantially more beneficial, this would provide scientific evidence for the value of live music therapy in the post-stroke period.</para>
      </section>
      <section id="id1164181943530">
        <title>4.2 Music and the recovery of verbal fluency in aphasia</title>
        <para id="id1164172999977">Aphasia is a language impairment due to central neurological dysfunction. Given the importance of language to human communication, aphasia is a truly debilitating neurological disorder affecting over 100,000 stroke victims each year in the U.S. alone (Schlaug et al., 2008). Nonfluent aphasias generally result from lesions in the frontal lobe and/or its underlying white matter fiber tracts, and are characterized by limited, effortful verbal output, often in the face of otherwise intelligent behavior. Such patients have difficulty retrieving the words they want to say and assembling the words into coherent phrases. Yet a striking phenomenon in many such patients, known for over one hundred years, is that they can sometimes sing familiar songs with great fluency (Racette et al., 2006). This led to the development of a form of aphasia therapy known as melodic intonation therapy, or MIT (Albert et al., 1973), which embeds short phrases (e.g., “I love you”) in “melodic” speech intonation patterns that rely on up-and-down movements between two discrete pitches. Patients practice such utterances intensively and regularly with a therapist, who gradually lengthens the phrases to span more syllables (Norton et al., 2009). The goal of the therapy is to improve fluency for both the trained phrases and for spontaneous, untrained utterances spoken in a normal fashion.</para>
        <para id="id8137470">Two features of MIT that distinguish it from non-musical speech therapy are the use of melodic speech intonation and rhythmic tapping (i.e., while speaking the utterance, the patient also taps its rhythm using the hand that was unaffected by the stroke). Schlaug and colleagues have recently begun a set of studies aimed at measuring the efficacy of MIT versus a matched “speech repetition therapy” (SRT) without melodic intonation and tapping. In addition to quantifying MIT’s versus SRT’s effects on post-therapy measures of verbal fluency, the researchers are also measuring changes in brain physiology after the two therapies. Of particular interest in this regard is the extent to which MIT patients shift toward using right hemisphere circuits for speech after therapy. Prior neuroimaging research with normal individuals indicates that song and speech have different hemispheric biases, with song activating several right hemisphere regions not activated by ordinary speech (Callan et al., 2006; cf. Peretz, in press). Hence, one question of interest is the extent to which MIT recruits these regions to compensate for damaged left-hemisphere regions.</para>
        <para id="id5777015">Preliminary data reported in Schlaug et al. (2008) support this idea by showing that a patient who underwent forty sessions of MIT showed greater verbal fluency and greater right hemisphere activation when speaking than did a patient who underwent SRT. Furthermore, Schlaug et al. (2009) have reported structural changes in the brains of several patients who underwent MIT. Specifically, these patients show an increase in the thickness of a large fiber tract (the right arcuate fasciculus) connecting the frontal and superior temporal lobes. Furthermore, there was a trend for a correlation between the degree of thickening and the degree of improvement in verbal fluency, though the trend did not reach statistical significance, possibly due to the small sample size (more patients are currently being studied).<footnote id="id1164170210361">Structural measures of the right arcuate fasciculus were conducted before and after seventy-five sessions of MIT therapy using MRI diffusion tensor imaging (DTI) in living patients. </footnote></para>
        <para id="id1164170725347"> Since this research program is still in its early stages, the findings raise numerous questions, including the reliability of the above correlation when more patients are added and the degree to which changes in the right arcuate fasciculus are specifically driven by MIT (versus SRT or no therapy). Furthermore, the physiological basis of the observed fiber-tract thickening is not yet clear. For example, such thickening could be due to use-related increases in the number of axon collaterals in the fasciculus or use-related increases in the diameter of existing axons.<footnote id="id1164170395106">I thank Robert Turner for bringing this point to my attention.</footnote> Nevertheless, the research of Schlaug and colleagues suggests that musical behaviors can have lasting effects on nonmusical brain functions after stroke. Furthermore, this research provides a model for studies seeking to examine the effects of music on other brain functions, as discussed in the next section. </para>
      </section>
      <section id="id1164182988707">
        <title>4.3 The biological power of music: future directions</title>
        <para id="id5777831">The two examples above suggest that music can have lasting effects on nonmusical abilities. The second example provides only preliminary data, but was included because it illustrates the kind of approach needed for studying the biological effects of music on brain function. Specifically, there is a need for experimental studies that combine longitudinal behavioral and neural measurements to examine how music influences nonmusical abilities in a lasting fashion (cf. Altenmüller et al., 2009). While studies that collect brain data are particularly valuable, purely behavioral studies are also useful if they lead to hypotheses for underlying neural mechanisms, as in the Särkämö study above. Well-controlled studies from the field of music therapy are of considerable interest in this regard (e.g., Bradt et al., in press).</para>
        <para id="id1164179853570"> While the examples above focused on adults, an important direction for future work concerns children, because their developing brains are even more malleable than those of adults (Huttenlocher, 2002). Indeed, music may be a particularly efficacious technology for shaping brain function in children because they are drawn to music from a very young age, meaning that it is relatively easy to get them to engage in musical behaviors repeatedly.</para>
        <para id="id1164170081548">An example from research on dyslexia helps illustrate how music might benefit the nonmusical abilities of children. Research has revealed that many children with developmental dyslexia have reduced sensitivity to auditory cues related to the amplitude envelope of sounds, such as the rise-time of syllables (the rate of sound amplitude increase at syllable onset). This auditory deficit appears to be related to their dyslexia: individual differences in rise time discrimination are predictive of phonological awareness, even when factors such as age, verbal and nonverbal IQ, and vocabulary are controlled (Goswami, 2009). Thus, sensitivity to the details of speech amplitude envelopes may play an important role in speech comprehension and in the development of the phonological system (cf. Greenberg, 2006). Neural studies using EEG have shown that the right cerebral hemisphere is particularly adept at tracking the amplitude envelope of speech in normal children (Abrams et al., 2008) and that poor readers have a degraded neural representation of the speech amplitude envelope (Abrams et al., 2009). </para>
        <para id="id1164174914741">What does this have to do with music? Rise-time is not only an important cue not only for speech, but also for music, e.g., in specifying the “perceptual attack” of musical sounds (Caclin et al., 2005). Thus, musical activities that make acoustic onsets salient and focus on the ability to accurately perceive such onsets, such as games involving clapping to syllable onsets of words in songs, may help refine brain networks involved in encoding amplitude patterns in ordinary speech (Goswami, 2009; cf. Overy, 2003; Tallal and Gaab, 2006). Experimental studies are needed to address this issue.</para>
        <para id="id1164170652270">Studies of the biological power of music need not be limited to individuals with neural anomalies. There is considerable scope for the study of how music affects the development of nonmusical abilities in ordinary individuals, both children and adults (Moreno, 2009). For example, Moreno et al. (2009) recently conducted an experiment in which normal third graders were pseudo-randomly assigned to nine months of music vs. painting lessons. They found that after musical (but not painting) training, children showed enhanced reading and improved pitch discrimination in speech, with the latter improvement shown by both behavioral and neural measures. While the study of how music lessons influence the development of reading is of great practical interest, the relationship between musical training and proficiency at second-language learning also merits study (Patel and Iversen, 2007), as does the relationship between musical training and executive function (Bialystock and DePape, 2009). In addition to these cognitive effects of music, the influence of group musical activities on the development of empathy and cooperative behavior also deserves research attention (cf. Kirschner and Tomasello, in press).</para>
      </section>
    </section>
    <section id="id1164169863378">
      <title>5. Why would music have lasting effects on nonmusical brain functions? </title>
      <para id="id1164169863385">The preceding section provided two examples of the lasting effects of music on nonmusical cognitive abilities. I suspect that in the coming years, more and more evidence will accrue for the lasting effects of music on diverse aspects of human brain function. Thus, it is important to begin thinking about why music sometimes has these effects. That is, what mechanisms underlie these effects? A firm answer to this question requires a large set of empirical studies from which to draw inductive conclusions. In the meantime, however, it is possible to set forth some hypotheses that may help guide future work.</para>
      <para id="id1164179845618">I hypothesize that one set of mechanisms involves the neuroendocrine system, i.e., the regulation of hormones by the brain. Music appears to have a strong influence on the human limbic system (Peretz, 2010; Koelsch, 2010), an emotional regulation system with diverse subcortical (e.g., hippocampus, amygdala, cingulate) and cortical (e.g. orbitofrontal cortex) components, which is influenced by many descending inputs from wide regions of the cerebral cortex (Damasio, 1994). The mechanisms by which music influences the limbic system remain to be understood and may revolve in part around music’s ability to emulate emotionally significant vocal sounds (Juslin and Laukka, 2003; Snowdon and Teie, 2009), though this is clearly only part of the story. For the current purposes, the crucial point is that the limbic system projects to the hypothalamus, which in turn regulates the release of a broad range of hormones from the brain and various peripheral glands (e.g., oxytocin, cortisol, etc.). Hormones are blood-borne chemical messengers that can have long-lasting effects on a range of brain structures that have hormone receptors. For example, the hippocampus and amygdala have cortisol receptors, and chronically elevated cortisol (e.g., due to prolonged stress) can influence neuronal morphology and activity in these brain structures, as well as the birth of new cells in the adult hippocampus (Sapolsky, 2000). Since there is empirical evidence that listening to music can transiently reduce cortisol levels in adults and infants (Trehub and Nakata, 2002; Khalfa et al., 2003; Suda et al., 2008), this suggests one pathway by which regular musical listening may have lasting effects on the brain (cf. section 4.1 above). Of course, cortisol is just one hormone regulated by the brain, and it seems likely that many hormones (e.g., testosterone, vasopressin, etc.) are potentially influenced by music (Fukui et al., 2008). In all such cases, the critical point is that hormones can have long-lasting effects on the cells that they influence. Thus, neuroendocrine effects on the brain are conceptually and mechanistically distinct from transient neurotransmitter effects, e.g., the release of dopamine associated with musical chills (“goosebumps”) (Blood and Zatorre, 2001; Salimpoor et al., 2009). </para>
      <para id="id1164172978888">Of course, the fact that hormones <emphasis effect="italics">can</emphasis> have long-lasting effects on brain structure or function does not mean that they always <emphasis effect="italics">do </emphasis>have such effects. The degree to which neuroendocrine effects result in lasting changes to the brain likely depends on the state the brain is in when such effects occur. Rapidly changing nervous systems (e.g., the brains of healthy infants or of older adults in the period soon after a brain injury) may be particularly sensitive in this regard. Furthermore, there may be genetic factors (including variation in hormone receptor density) that influence tissue sensitivity to hormones.</para>
      <para id="id1164171163448"> Apart from neuroendocrine effects, I hypothesize that another way music can have lasting effects on nonmusical abilities is via mechanisms of neural plasticity, i.e. via use-dependent functional or structural changes in brain circuitry. (In contrast to neuroendocrine mechanisms, which can be activated by passive listening to music, plasticity-based mechanisms are likely to be driven by active engagement with music, e.g. via regular singing or playing of a musical instrument.) Modern neuroscience has shifted from a view of the brain as plastic only during early developmental periods to a view that recognizes a substantial degree of plasticity throughout the lifespan (Edelman, 1987; Draganski and May, 2008). The “permanent plasticity” of the brain means that the networks involved in our cognitive functions are malleable throughout life (though the degree of malleability in many brain areas may be substantially higher during early sensitive periods of development). According to TTM theory, music engages processing mechanisms shared with a wide range of cognitive domains, such as language, attention, auditory scene analysis, and so forth. Hence, music has the opportunity to influence these domains by driving plasticity in brain networks that it shares with these domains.</para>
      <para id="id1164169948062">Why would music drive plasticity in these networks? One idea is that music is often more exacting than other domains in terms of the degree of precision that it demands. For example, music and speech both involve the control of pitch, but music demands a higher degree of precision for both the control and perception of pitch than does ordinary speech (Patel, 2008, Ch. 4). Thus, musical experience may sharpen cortical and subcortical pitch processing mechanisms shared by music and language, leading to the observed superior processing of linguistic pitch contours by musicians (Wong et al., 2007; Patel and Iversen, 2007). Similar arguments may help explain why musically trained individuals show superior perception of speech in noise (Parbery-Clark et al., 2009) and other nonmusical auditory processing benefits.</para>
      <para id="id1164177842254">Apart from the demands of high-precision processing, another factors that may promote music’s ability to drive plasticity is the fact that musical behaviors are often frequently repeated (e.g., frequently singing or playing a particular piece) and often involve heightened emotion. Repeatedly engaging in high-precision processing in the context of heightened emotion seems likely to promote functional and structural changes to the brain.</para>
    </section>
    <section id="id1164170759411">
      <title>6. A non-genetic explanation for music’s universality</title>
      <para id="id1164173045682">Thus far, this essay has argued that music is an invention. Yet if it is an invention, why is it universal in human culture? Section 3 pointed out that human cultural universals can originate as inventions, as illustrated by the control of fire. TTM theory posits that music resembles fire-making in being an ancient invention that has become universal because it provides things that are universally valued by humans. In the case of fire, these things include the ability to cook food, keep warm, and see in dark places. In the case of music, I suggest that the valued things it provides are mental rather than physical: namely, emotional power, ritual efficacy, and mnemonic efficacy.</para>
      <section id="id1164170127747">
        <title>6.1 Emotional power</title>
        <para id="id1164170127753">Many people report listening to music for the emotion it induces (Juslin and Sloboda, 2001; Benzon, 2001). Emotions are important for humans everywhere from the very beginning of life, and hence one reason for music’s universality may be its deep connection to the brain’s emotional circuitry (Peretz, 2010, Koelsch, 2010). This connection could help explain the human proclivity for music without postulating any “innate proclivity for musical sounds and actions” (Kirschner and Tomasello, in press).</para>
        <para id="id1164169391211">However, this is a rather unsatisfying explanation for music’s universality, because it only serves to raise more questions. <emphasis effect="italics">Why</emphasis> does music have these connections to the emotion circuits of our brains? Can the remarkable power of music to induce emotion be explained without appealing to an evolutionary specialization of the brain for music? In this regard, a recent theory of emotional induction by music is of interest (Juslin and Västfjäll, 2008). According to this “multiple mechanisms” theory, music can induce emotion in several different ways, namely via 1) expectancy and its fulfillment or violation; 2) activation of the brainstem by arousing acoustic features (e.g., sudden, sharp onsets); 3) association with past events; 4) visual imagery; or 5) acoustic cues that resemble the sounds of emotional voices. For the current purposes, the salient aspect of Juslin and Västfjäll’s theory is that none of the proposed emotion-inducing mechanisms is unique to music. For example, focusing on the first mechanism, auditory expectation and its relationship to emotion may be a very general aspect of human cognition, not shaped <emphasis effect="italics">for</emphasis> music but exquisitely exploited <emphasis effect="italics">by</emphasis> music (see Huron, 2006, for a detailed theory, and Steinbeis et al., 2006, for empirical data linking musical expectancy to emotion). Focusing on the final mechanism, the authors postulate that this aspect of music’s emotional power is due to brain mechanisms that evolved to perceive and respond to vocal affect (cf. Patel 2008b).</para>
        <para id="id1164170111873"> Thus, music’s remarkable emotional power may arise via its ability to simultaneously engage multiple emotional mechanisms in our brains. While none of these mechanisms is unique to music, music may be unique in the way it temporally activates and coordinates these mechanisms. The result is a complex emotional experience that can differ from our ordinary day-to-day emotions. This might help explain reports of “music-specific” or “aesthetic” emotions (Zentner et al., 2008), which seem qualitatively distinct from basic emotions associated with survival, such as happiness, sadness, fear, or anger. </para>
      </section>
      <section id="id5756315">
        <title>6.2 Ritual efficacy</title>
        <para id="id1164173206531">All human cultures have rituals, and music provides a very useful framework for certain types of rituals, independent of the emotional impact of the music <emphasis effect="italics">per se</emphasis>. This is because music provides a structure that can easily be repeated on different occasions, and because musical behaviors are distinct from our ordinary communication. In modern culture, the group singing of “Happy Birthday” provides a familiar example. The performance and appreciation of this song is typically not concerned with the aesthetic or emotional qualities of the music. Rather, the song serves as a ritual that effectively means “we collectively recognize and celebrate your birthday.” </para>
      </section>
      <section id="id1164169957696">
        <title>6.3 Mnemonic efficacy</title>
        <para id="id1164170654360">In addition to emotion and ritual, music often provides an important mnemonic device for storing long sequences of linguistic information, especially when written language is not available (Sloboda, 1985). In this regard, it is notable that music and song are part of most of the world’s ancient oral traditions, e.g., epics and religious chants from diverse civilizations (Rubin, 1995). In our own culture, a familiar example of the mnemonic efficacy of music is the alphabet song, a tune used by many children to learn the order of letters in the alphabet. One indication of music’s remarkable power to enter into human memory comes from clinical research with Alzheimer’s patients. Experiments with such patients indicate that memory of songs is retained in substantial detail, even in the face of significant loss of episodic memories concerning the patient’s own life (Cuddy and Duffin, 2005). The neural mechanisms behind music’s mnemonic efficacy are in need of systematic research.</para>
      </section>
    </section>
    <section id="id1164175181871">
      <title>7. A Darwinian perspective on the biological study of music </title>
      <para id="id1164171413698">Evolutionary discussions of music originate with Darwin, so it is fitting to end this essay with a comment on the relevance of Darwin’s thinking to the current proposal. TTM theory proposes that music is an invention that builds on a diverse range of brain functions and has the ability to shape those functions. Thus, TTM theory, unlike Darwin’s theory of music, is nonadaptationist. Yet it is thoroughly Darwinian in its focus on comparative biological research. As illustrated by section 3 (“Music as a human invention”), TTM theory grows from studies comparing music processing to brain processing in other domains (such as language) and studies comparing music processing to auditory processing in other species. TTM theory is thus committed to using Darwinian research methods to explore the neurobiological foundations of human music.</para>
      <para id="id1164173201306">Before closing, it is worth asking what distinguishes TTM theory from the concept of exaptation, or a trait whose evolutionary origin is not related to its current use (Gould and Vrba, 1982). Feathers are an oft-cited example of an exaptation, as it has been theorized that these structures originated in the context of thermoregulation and were only later put to use (and directly shaped by natural selection) for flight (Gould and Vrba, 1982). Since TTM theory views music as an invention based on diverse nonmusical brain functions, each of which may have been shaped by natural selection, it considers music a type of exaptation. However, exaptation is not a specific enough term to capture the idea of a transformative technology. This is because exaptation (a term coined before our modern understanding of neural plasticity) does not connote the power of a novel trait to shape the biological systems from which it arose (cf. Lewontin, 2000). Furthermore, exaptation allows the notion of secondary adaptation (as in the feather example above), whereas TTM theory holds that that there has been no evolutionary modification of the brain aimed at supporting musical behavior. </para>
      <para id="id1164171070263">Darwin himself was not an ultra-adaptationist; that is, he did not believe that every characteristic of an organism was a product of natural selection. (He differed from his contemporary Alfred Russell Wallace in this regard [Gould, 1980].) For example, in <emphasis effect="italics">The Descent of Man</emphasis>, Darwin wrote that “many cases could be advanced of organs and instincts originally adapted for one purpose, having been utilized for some distinct purpose” (p. 1208). That is, he implicitly recognized the concept of exaptation long before the term was coined by later evolutionary biologists. What Darwin did not foresee, however, was that human inventions could substantially influence the structure and function of the brain, albeit within the course of a lifetime. This remarkable fact lays the foundation for a biological approach to music and other human cultural phenomena (Wilson, 1998; Becker, 2004; Edelman, 2006; Smail, 2008). Understanding the biology of human inventions involves understanding how our evolved neural organization shapes those inventions <emphasis effect="italics">and</emphasis> how our inventions in turn shape our brains within individual lifetimes. In exploring this fascinating dialectic, music is a particularly promising area of research.</para>
    </section>
    <section id="id1164186238378">
      <title>Acknowledgments</title>
      <para id="id1164170081320">Supported by Neurosciences Research Foundation as part of its research program on music and the brain at The Neurosciences Institute, where ADP is the Esther J. Burnham Senior Fellow. I am grateful to the following individuals for their insightful comments: Jennifer Burton, John Iversen, Sebastian Kirschner, Richard Lewontin, Bruno Repp, Oliver Sacks, Robert Sapolsky, Thom Scott-Phillips, Daniel Smail, Lauren Stewart, William Forde Thompson, and Ellen Winner. I also thank Melissa Bailar for thoughtful editing, and Fred Moody for his prompt and helpful input throughout the publication process.</para>
    </section>
    <section id="id1164183605037">
      <title>References</title>
      <para id="id1164183605045">Abrams, D.A., Nicol, T., Zecker, S., and Kraus, N. (2008). Right hemisphere auditory cortex is dominant for coding syllable patterns in speech. <emphasis effect="italics">The Journal of Neuroscience,</emphasis> 28, 3958–3965.</para>
      <para id="id1164180639192">Abrams, D.A., Nicol, T., Zecker, S., and Kraus, N. (2009). Abnormal cortical processing of the syllable rate of speech in poor readers. <emphasis effect="italics">The Journal of Neuroscience, </emphasis>29, 7686–7693.</para>
      <para id="id1164175158968">Albert, M.L., Sparks, R.W., and Helm, N.A. (1973). Melodic intonation therapy for aphasia. <emphasis effect="italics">Archives of Neurology, </emphasis>29, 130-131.</para>
      <para id="id1164173171226">Altenmüller, E., Marco-Pallares, J., Münte, T. F., and Schneider, S. (2009). Neural reorganization underlies improvement of stroke-induced motor dysfunction by music-supported therapy. <emphasis effect="italics">Annals of the New York Academy of Sciences,</emphasis> 1169, 395–405.</para>
      <para id="id1164170178092">Becker, J. (2004). <emphasis effect="italics">Deep Listeners: Music, Emotion, and Trancing</emphasis>. Bloomington: Indiana University Press.</para>
      <para id="id1164170178101">Bengtsson, S.L., Nagy, Z., Skare, S., et al. (2005). Extensive piano practicing has regionally specific effects on white matter development. <emphasis effect="italics">Nature Neuroscience</emphasis>, 8, 1148-1151.</para>
      <para id="id1164170072642">Benzon, W. (2001). <emphasis effect="italics">Beethoven's Anvil: Music in Mind and Culture.</emphasis> New York: Basic Books.</para>
      <para id="id8384121">Bialystock, E. and DePape, A. (2009). Musical expertise, bilingualism, and executive functioning. <emphasis effect="italics">Journal of Experimental Psychology: Human Perception and Performance</emphasis>, 35, 565–574.</para>
      <para id="id1164173182908">Bigand, E. and Poulin-Charronnat, B. (2006). Are we “experienced listeners”? A review of the musical capacities that do not depend on formal musical training. <emphasis effect="italics">Cognition, </emphasis>100, 100–130.</para>
      <para id="id1164170971796">Bigand, E., Poulin, B., Tillmann, B., Madurell, F., and D’Adamo, D.A. (2003). Sensory versus cognitive components in harmonic priming. <emphasis effect="italics">Journal of Experimental Psychology: Human Perception and Performance, </emphasis>29, 159–171.</para>
      <para id="id1164170971805">Bispham, J. (2006). Rhythm in music: What is it? Who has it? And why? <emphasis effect="italics">Music Perception,</emphasis> 24, 125-134.</para>
      <para id="id1164170764020">Blacking, J. (1973). <emphasis effect="italics">How Musical is Man?</emphasis> Seattle: University of Washington.</para>
      <para id="id1164174292960">Blood, A.J. and Zatorre, R.J. (2001). Intensely pleasurable responses to music correlate with activity in brain regions implicated with reward and emotion. <emphasis effect="italics">Proceedings of the National Academy of Sciences</emphasis>, 98, 11818–11823.</para>
      <para id="id1164171225468">Boyd, B. (2009). <emphasis effect="italics">On the Origin of Stories: Evolution, Cognition, and Fiction.</emphasis> Cambridge, MA: Harvard University Press.</para>
      <para id="id1164183433720">Bradt, J., Magee, W.L., Dileo, C., Wheeler, B. and McGilloway, E. (in press). Music therapy for acquired brain injury. <emphasis effect="italics">Cochrane Database of Systematic Reviews.</emphasis></para>
      <para id="id1164171009165">Bregman, A.S. (1990). <emphasis effect="italics">Auditory Scene Analysis.</emphasis> Cambridge, MA: MIT Press.</para>
      <para id="eip-542">Brown, S. (2000(a)). The “musilanguage” model of music evolution. In: Wallin, N.L., Merker, B., and Brown, S. (Eds.), <emphasis effect="italics">The Origins of Music</emphasis> (pp. 271-300). Cambridge, MA: MIT Press.</para>
<para id="id1164170652461">Brown, S. (2000(b)). Evolutionary models of music: From sexual selection to group selection. In: Tonneau, F. and Thompson, N.S. (Eds.), <emphasis effect="italics">Perspectives in Ethology</emphasis>. 13: <emphasis effect="italics">Behavior, Evolution and Culture</emphasis> (pp. 231-281). New York: Plenum Publishers.</para>
      
      <para id="id8025589">Caclin, A., McAdams, S., Smith, B.K., and Winsberg, S. (2005). Acoustic correlates of timbre space dimensions: A confirmatory study using synthetic tones. <emphasis effect="italics">Journal of the Acoustic Society of America, </emphasis>118, 471–482.</para>
      <para id="id1164169776946">Callan, D., Tsytsarev, V., Hanakawa, T., et al. (2006). Song and speech: Brain regions involved with perception and covert production. <emphasis effect="italics">NeuroImage</emphasis>, 31, 1327–1342.</para>
      <para id="id1164174186877">Cohen, E., Ejsmond-Frey, R., Knight, N., and Dunbar, R. (2009). Rowers’ high: Elevated endorphin release under conditions of active behavioural synchrony. <emphasis effect="italics">Biology Letters</emphasis>, doi: 10.1098/rsbl.2009.0670.</para>
      <para id="id1164169863409">Cross, I. (2009). The nature of music and its evolution. In: Hallam, S., Cross, I., and Thaut, M. (Eds.), <emphasis effect="italics">The Oxford Handbook of Music Psychology</emphasis> (pp. 3-13). Oxford: Oxford University Press.</para>
      <para id="id1164169863419">Conard, N.J., Malina, M., and Münzel, S.C. (2009). New flutes document the earliest musical tradition in southwestern Germany. <emphasis effect="italics">Nature</emphasis>, 460, 737-740.</para>
      <para id="id1164169403058">Cuddy, L.L. and Duffin, J.M. (2005). Music, memory, and Alzheimer's Disease: Is music recognition spared in dementia, and how can it be assessed? <emphasis effect="italics">Medical Hypotheses,</emphasis> 64, 229-235.</para>
      <para id="id1164173977225">Dalla Bella, S., Kraus, N., Overy, K., et al. (2009). The Neurosciences and Music III: Disorders and Plasticity. <emphasis effect="italics">Annals of the New York Academy of Sciences</emphasis>, Vol. 1169.</para>
      <para id="id1164173977239">Damasio, A. (1994). <emphasis effect="italics">Descartes' Error: Emotion, Reason, and the Human Brain</emphasis>. New York: Putnam.</para>
      <para id="id1164170518831">Darwin, C. (1871). <emphasis effect="italics">The Descent of Man, and Selection in Relation to Sex. </emphasis>In: Wilson, E.O. (Ed.). <emphasis effect="italics">From So Simple a Beginning: The Four Great Books of Charles Darwin.</emphasis> New York: W.W. Norton (2006).</para>
      <para id="id5825413">Deacon, T.W. (1997). <emphasis effect="italics">The Symbolic Species: The Co-evolution of Language and the Brain</emphasis>. New York: W. W. Norton.</para>
      <para id="id1164169841578">Dehaene, S. (2009). <emphasis effect="italics">Reading in the Brain.</emphasis> New York: Viking.</para>
      <para id="id1164170651765">Dehaene, S. and Cohen, L. (2007). Cultural recycling of cortical maps. <emphasis effect="italics">Neuron,</emphasis> 56, 384-398.</para>
      <para id="id1164170503485">Dissanayake, E. (2008). If music is the food of love, what about survival and reproductive success? <emphasis effect="italics">Musicae Scientiae</emphasis> (Special Issue), 169-195.</para>
      <para id="id1164170327553">Draganski, B. and May, A. (2008). Training-induced structural changes in the adult human brain. <emphasis effect="italics">Behavioural Brain Research,</emphasis> 192, 137–142.</para>
      <para id="id1164171354148">Drayna, D., Manichaikul, A., de Lange, M., Snieder, H., and Spector, T. (2001). Genetic correlates of musical pitch recognition in humans. <emphasis effect="italics">Science</emphasis>, 291, 1969–72.</para>
      <para id="id1164183500036">Dunbar, R.I.M. (in press). On the evolutionary function of song and dance.
In: Bannan, N. (Ed.), <emphasis effect="italics">Music, Language and Human Evolution</emphasis>. Oxford: Oxford University Press. </para>
      <para id="id1164171188057">Edelman, G.M. (1987). <emphasis effect="italics">Neural Darwinism: The Theory of Neuronal Group Selection</emphasis>. New York: Basic Books.</para>
      <para id="id1164172654243">Edelman, G.M. (2006). <emphasis effect="italics">Second Nature: Brain Science and Human Knowledge</emphasis>. New Haven: Yale University Press.</para>
      <para id="id1164171540148">Eerola, T., Luck, G., and Toiviainen, P. (2006). An investigation of pre-schoolers’ corporeal synchronization with music. In: Baroni, M., Addessi, A., Caterina R., and Costa, M. (Eds.), <emphasis effect="italics">Proceedings of the 9th International Conference on Music Perception and Cognition (ICMPC9)</emphasis> (pp. 472–476). Bologna, Italy.</para>
      <para id="id1164179153906">Elbert, T., Pantev, C., Wienbruch, C., Rockstroh, B., and Taub, E. (1995). Increased use of the left hand in string players associated with increased cortical representation of the fingers. <emphasis effect="italics">Science</emphasis>, 270, 305–307.</para>
      <para id="id1164169687828">Everett, D.L. (2008). <emphasis effect="italics">Don't Sleep, There Are Snakes: Life and Language in the Amazonian Jungle</emphasis>. New York: Pantheon.</para>
      <para id="id1164187485825">Falk, D. (2004). Prelinguistic evolution in early hominins: Whence motherese? <emphasis effect="italics">Behavioral and Brain Sciences</emphasis>, 27, 491-503.</para>
      <para id="id1164171319511">Fedorenko, E., Patel, A.D., Casasanto, D., Winawer, J., and Gibson, E. (2009). Structural integration in language and music: Evidence for a shared system. <emphasis effect="italics">Memory and Cognition</emphasis>, 37, 1-9.</para>
      <para id="id1164170654969">Fitch, W.T. (2006). The biology and evolution of music: A comparative perspective. <emphasis effect="italics"> Cognition</emphasis>, 100, 173–215.</para>
      <para id="id1164170802484">Fitch, W.T. (2010). <emphasis effect="italics">The Evolution of Language</emphasis>. Cambridge: Cambridge University Press. </para>
      <para id="id1164170136472">Fisher, S.E. and Franks, C. (2006). Genes, cognition and dyslexia: Learning to read the genome. <emphasis effect="italics">Trends in Cognitive Sciences</emphasis>, 10, 250-257.</para>
      <para id="id1164170846933">Fukui, H. and Toyoshima, K. (2008). Music facilitates the neurogenesis, regeneration and repair of neurons. <emphasis effect="italics">Medical Hypotheses</emphasis>, 71, 765–769.</para>
      <para id="id1164170974820">Geissmann, T. (2000). Gibbon songs and human music from an evolutionary perspective. In: Wallin, N.L., Merker, B., and Brown, S. (Eds.), <emphasis effect="italics">The Origins of Music </emphasis>(pp. 102–123). Cambridge, MA: MIT Press.</para>
      <para id="id1164176647538">Gibson, E. (1998). Linguistic complexity: Locality of syntactic dependencies. <emphasis effect="italics">Cognition</emphasis>, 68, 1-76.</para>
      <para id="id1164183087055">Gibson, E. (2006). The interaction of top–down and bottom–up statistics in the resolution of syntactic category ambiguity. <emphasis effect="italics">Journal of Memory and Language</emphasis>, 363-388. </para>
      <para id="id8070538">Goldstein, T.R., Wu, K., and Winner, E. (2009-2010). Actors are skilled in theory of mind but not empathy. <emphasis effect="italics">Imagination, Cognition, and Personality, </emphasis>29, 115-133.</para>
      <para id="id1164174299602">Goswami, U. (2009). Mind, brain, and literacy: Biomarkers as usable knowledge for education. <emphasis effect="italics">Mind, Brain, and Education</emphasis>, 3, 176-184.</para>
      <para id="id1164171549494">Gould, S.J. (1980). Natural selection and the brain: Darwin vs. Wallace. In: <emphasis effect="italics">The Panda's Thumb</emphasis> (pp. 47-58). New York: Norton.</para>
      <para id="id1164173779766">Gould, S.J. and Vrba, C. (1982). Exaptation— a missing term in the science of form. <emphasis effect="italics">Paleobiology</emphasis>, 8, 4-15.</para>
      <para id="id1164173464412">Greenberg, S. (2006). A multi-tier framework for understanding spoken language. In: Greenberg, S. and Ainsworth, W.A. (Eds.), <emphasis effect="italics">Listening to Speech: An Auditory Perspective</emphasis> (pp. 411–433). Mahwah, NJ: Erlbaum.</para>
      <para id="id1164170337126">Greenfield, M.D. and J. Schul. (2008). Mechanisms and evolution of synchronous chorusing: emergent properties and adaptive functions in Neoconocephalus katydids (Orthoptera: Tettigoniidae). <emphasis effect="italics">Journal of Comparative Psychology</emphasis>, 122, 289–297.</para>
      <para id="id1164170760179">Hagen, E.H. and Hammerstein, P. (2009). Did Neanderthals and other early humans sing? Seeking the biological roots of music in the loud calls of primates, lions, hyenas, and wolves. <emphasis effect="italics">Musicae Scientiae</emphasis>, Special Issue 2009/10 "Music and Evolution," 291-320.</para>
      <para id="id1164169484589">Hauser, M. D. and McDermott, J. (2003). The evolution of the music faculty: A comparative perspective. <emphasis effect="italics">Nature Neuroscience</emphasis>, 6, 663–668.</para>
      <para id="id1164171187535">Huron, D. (2006). <emphasis effect="italics">Sweet Anticipation: Music and the Psychology of Expectation.</emphasis> Cambridge, MA: MIT Press.</para>
      <para id="id1164173169430">Huttenlocher, P. (2002). <emphasis effect="italics">Neural Plasticity: The Effects of Environment on the Development of the Cerebral Cortex</emphasis>. Cambridge, MA: Harvard University Press.</para>
      <para id="id1164170782430">Hyde, K., Lerch, J., Norton, A., et al. (2009). Musical training shapes structural brain development. <emphasis effect="italics">The Journal of Neuroscience</emphasis>, 29, 3019 –3025.</para>
      <para id="id1164169804002">Jackendoff, R. (2009). Parallels and nonparallels between language and music. <emphasis effect="italics">Music Perception</emphasis>, 26, 195–204.</para>
      <para id="id1164186163904">James, W. (1890). <emphasis effect="italics">The Principles of Psychology</emphasis>. New York: Dover Publications.</para>
      <para id="id1164170450460">Janata, P., Tillmann, B., and Bharucha, J. (2002). Listening to polyphonic music recruits domain-general attention and working memory circuits. <emphasis effect="italics">Cognitive, Affective, and Behavioral Neuroscience</emphasis>, 2, 121-140.</para>
      <para id="id1164173700225">Jarvis, E.D. (2007). Neural systems for vocal learning in birds and humans: A synopsis. <emphasis effect="italics">Journal of Ornithology,</emphasis> 148 (Suppl. 1), S35-S44.</para>
      <para id="id1164171198033">Jarvis, E.D. (2009). Bird song systems: Evolution. In: L.R. Squire et al. (Eds.), <emphasis effect="italics">Encyclopedia of Neuroscience, </emphasis>vol. 2, (pp. 217-225). Oxford: Academic Press.</para>
      <para id="id8938871">Jentschke, S., Koeslch, S., Sallat, S., and Friederici, A. (2008). Children with specific language impairment also show impairment of music-syntactic processing. <emphasis effect="italics">Journal of Cognitive Neuroscience</emphasis>, 20, 1940-1951.</para>
      <para id="id1164170934946">Juslin, P. N. and Laukka, P. (2003). Communication of emotions in vocal expression and music performance: Different channels, same code? <emphasis effect="italics">Psychological Bulletin</emphasis>, 129, 770–814.</para>
      <para id="id1164170884385">Juslin, P. N. and Sloboda, J. A. (Eds.). (2001). <emphasis effect="italics">Music and Emotion: Theory and Research</emphasis>. Oxford, UK: Oxford University Press.</para>
      <para id="id1164186506681">Juslin, P. N. and Västfjäll, D. (2008). Emotional responses to music: The need to consider underlying mechanisms. <emphasis effect="italics">Behavioral and Brain Sciences</emphasis>, 31, 559–621.</para>
      <para id="id1164173389414">Justus, T. and Hutsler, J.J. (2005). Fundamental issues in the evolutionary psychology of music: Assessing innateness and domain-specificity. <emphasis effect="italics">Music Perception</emphasis>, 23, 1–27.</para>
      <para id="id8104421">Khalfa, S., Dalla Bella, S., Roy, M., et al. (2003). Effects of relaxing music on salivary cortisol level after psychological stress.<emphasis effect="italics"> Annals of the New York Academy of Sciences</emphasis>, 999, 374-376.</para>
      <para id="id1164171337716">Kirschner, S. and Tomasello, M. (in press). Joint music making promotes prosocial behavior in four-year-old children. <emphasis effect="italics">Evolution and Human Behavior.</emphasis></para>
      <para id="id1164169582840">Kivy, P. (1959). Charles Darwin and Music. <emphasis effect="italics">Journal of the American Musicological Society</emphasis>, 12, 42-48.</para>
      <para id="id1164169959496">Kivy, P. (1960). <emphasis effect="italics">Herbert Spencer and a musical dispute.</emphasis> Masters Thesis, Yale University Deptartment of Music.</para>
      <para id="id1164178455178">Kivy, P. (1964). Herbert Spencer and a Musical Dispute. <emphasis effect="italics">Music Review</emphasis>, 23, 317-329.</para>
      <para id="id1164175297570">Koelsch, S. (2010). Towards a neural basis of music-evoked emotions. <emphasis effect="italics">Trends in Cognitive Sciences,</emphasis> 14, 131-137.</para>
      <para id="id1164170525816">Koelsch, S., Gunter, T.C., von Cramon, D.Y., Zysset, S., Lohmann, G., and Friederici, A.D. (2002). Bach speaks: A cortical “language-network” serves the processing of music. <emphasis effect="italics">NeuroImage</emphasis>, 17, 956–966.</para>
      <para id="id1164171573278">Koelsch S., Gunter T.C., Wittforth, M., and Sammler, D. (2005). Interaction between syntax processing in language and music: An ERP study. <emphasis effect="italics">Journal of Cognitive Neuroscience</emphasis>, 17, 1565-1577.</para>
      <para id="id1164170324174">Koelsch, S., Jentschke, S., Sammler, D., and Mietchen, D. (2007). Untangling syntactic and sensory processing: An ERP study of music perception. <emphasis effect="italics">Psychophysiology</emphasis>, 44, 476–490.</para>
      <para id="id1164170600938">Kosfeld, M., Heinrichs, M., Zak, P.J., et al. (2005). Oxytocin increases trust in humans. <emphasis effect="italics">Nature,</emphasis> 435, 673–676.</para>
      <para id="id1164170210346">Krumhansl, C.L. (1990). <emphasis effect="italics">Cognitive Foundations of Musical Pitch</emphasis>. New York: Oxford University Press.</para>
      <para id="id1164175225472">Krumhansl, C.L. and Cuddy, L.L. (in press). A theory of tonal hierarchies in music. In: Popper, A.N., Fay, R.R., and Jones, M.R. (Eds.), <emphasis effect="italics">Music Perception: Springer Handbook of Auditory Research</emphasis>. New York: Springer-Verlag.</para>
      <para id="id1164170068347">Lee, N., Mikesell, L., Joaquin, A.D.L., et al. (2009). <emphasis effect="italics">The Interactional Instinct</emphasis>. New York: Oxford University Press.</para>
      <para id="id1164171145846">Leins, A.K., Spintge, R., and Thaut, M. (2009). Music therapy in medical and neurological rehabilitation settings. In: Hallam, S. et al. (Eds.). <emphasis effect="italics">The Oxford Handbook of Music Psychology </emphasis>(pp. 526-535).</para>
      <para id="id1164170854596">Lerdahl, F., and Jackendoff, R. (1983). <emphasis effect="italics">A Generative Theory of Tonal Music</emphasis>. Cambridge, MA: MIT Press.</para>
      <para id="id1164173702894">Levy, R. (2008). Expectation-based syntactic comprehension. <emphasis effect="italics">Cognition</emphasis>, 106<emphasis effect="italics">,</emphasis> 1126-1177.</para>
      <para id="id1164170275195">Lewontin, R. (2000). <emphasis effect="italics">The Triple Helix: Gene, Organism and Environment</emphasis>. Cambridge, MA: Harvard University Press.</para>
      <para id="id1164174083041">Livingstone, S. and Thompson, W.F. (2009). The emergence of music from the Theory of Mind. <emphasis effect="italics">Musica Scientiae</emphasis>, Special Issue 2009/10 “Music and Evolution,” 83-115.</para>
      <para id="id1164171082719">Maess, B., Koelsch, S., Gunter, T., and Friederici, A. D. (2001). Musical syntax is processed in Broca’s area: An MEG study. <emphasis effect="italics">Nature Neuroscience</emphasis>, 4, 540–545.</para>
      <para id="id1164171245270">Mar, R., Djikic, M., and Oatley, K. (2008). Effects of reading on knowledge, social abilities, and selfhood. In: Zyngier, S. et al. (Eds.), <emphasis effect="italics">Directions in Empirical Literary Studies: In Honor of Willie van Peer</emphasis> (pp. 127-137). Amsterdam: Benjamins.</para>
      <para id="id1164169430088">McMullen, E. and Saffran, J. R. (2004). Music and language: A developmental comparison. <emphasis effect="italics">Music Perception</emphasis>, 21, 289–311.</para>
      <para id="id1164169312359">Merker, B. (2000). Synchronous chorusing and human origins. In: Wallin, N.L., Merker, B., and Brown, S. (Eds.), <emphasis effect="italics">The Origins of Music </emphasis>(pp. 315–327). Cambridge, MA: MIT Press.</para>
      <para id="id1164172965429">Merker, B., Madison, G., and Eckerdal, P. (2009). On the role and origin of isochrony in human rhythmic entrainment. <emphasis effect="italics">Cortex,</emphasis> 45, 4-17.</para>
      <para id="id1164173178443">McAuley, J.D., Jones, M.R., Holub, S., et al. (2006). The time of our lives: Lifespan development of timing and event tracking. <emphasis effect="italics">Journal of Experimental Psychology: General</emphasis>, 135, 348-367.</para>
      <para id="id1164170923930">McNeill, W. H. (1995). <emphasis effect="italics">Keeping Together in Time: Dance and Drill in Human History.</emphasis> Cambridge, MA: Harvard University Press.</para>
      <para id="id1164177532923">Menon, V. and Levitin, D.J. (2005). The rewards of music listening: Response and physiological connectivity of the mesolimbic system. <emphasis effect="italics">NeuroImage</emphasis>, 28, 175-184.</para>
      <para id="id1164173031437">Miller, G. (2000). Evolution of human music through sexual selection. In: Wallin, N.L., Merker, B., and Brown, S. (Eds.), <emphasis effect="italics">The Origins of Music </emphasis>(pp. 329–360). Cambridge, MA: MIT Press.</para>
      <para id="id1164180773846">Mithen, S. (2005). <emphasis effect="italics">The Singing Neanderthals: The Origins of Music, Language, Mind and Body</emphasis>. London: Weidenfeld and Nicolson.</para>
      <para id="id1164170854806">Moreno, S. (2009). Can music influence language and cognition? <emphasis effect="italics">Contemporary Music Review,</emphasis> 28, 329-345.</para>
      <para id="id1164174550084">Moreno, S., Marques, C., Santos, A., et al. (2009). Musical training influences linguistic abilities in 8-year-old children: More evidence for brain plasticity. <emphasis effect="italics">Cerebral Cortex. </emphasis>19, 712-723.</para>
      <para id="id1164186397935">Nettl, B. (2000). An ethnomusicologist contemplates universals in musical sound and musical culture. In: Wallin, N.L., Merker, B., and Brown, S. (Eds.), <emphasis effect="italics">The Origins of Music </emphasis>(pp. 463–472). Cambridge, MA: MIT Press.</para>
      <para id="id1164170752456">Nettl, B. and Stone, R. (1998). <emphasis effect="italics">The Garland Encyclopedia of World Music (10 vols)</emphasis>. New York: Garland Publications.</para>
      <para id="id1164175873879">Norton, A., Zipse, L., Marchina, S., and Schlaug, G. (2009). Melodic intonation therapy: Shared insights on how it is done and why it might help. <emphasis effect="italics">Annals of the New York Academy of Sciences</emphasis>, 1169, 431-436.</para>
      <para id="id1164171235174">Overy, K. (2003). Dyslexia and music: From timing deficits to musical intervention. <emphasis effect="italics">Annals of the New York Academy of Sciences</emphasis>, 999, 497-505.</para>
      <para id="id1164169464320">Panksepp, J. (2009). The emotional antecedents to the evolution of music and language. <emphasis effect="italics">Musicae Scientiae</emphasis>, Special Issue 2009/10 “Music and Evolution,” 229-259.</para>
      <para id="id1164169405721">Parbery-Clark, A., Skoe, E., Kraus, N. (2009). Musical experience limits the degradative effects of background noise on the neural processing of sound. <emphasis effect="italics">Journal of Neuroscience</emphasis>, 29, 14100-14107.</para>
      <para id="id8129820">Patel, A.D. (2003). Language, music, syntax, and the brain. <emphasis effect="italics">Nature Neuroscience</emphasis>, 6, 674–681.</para>
      <para id="id1164170241360">Patel, A.D. (2006). Musical rhythm, linguistic rhythm, and human evolution. <emphasis effect="italics">Music Perception</emphasis>, 24, 99-104.</para>
      <para id="id1164170818381">Patel, A.D. (2008). <emphasis effect="italics">Music, Language, and the Brain</emphasis>. New York: Oxford University Press.</para>
      <para id="id1164170896822">Patel, A.D. (2008b). A neurobiological strategy for exploring links between emotion recognition in music and speech. <emphasis effect="italics">Behavioral and Brain Sciences</emphasis>, 31, 589-590.</para>
      <para id="id1164170799753">Patel, A.D. (in press(a)). Language, music, and the brain: A resource-sharing framework. In: Rebuschat, P., Rohrmeier, M., Hawkins, J., and Cross, I. (Eds.),<emphasis effect="italics"> Language and Music as Cognitive Systems</emphasis>. Oxford: Oxford University Press.</para>
      <para id="id1164173825050">Patel, A.D. (in press(b)). Advancing the comparative study of linguistic and musical syntactic processing. In: Rebuschat, P., Rohrmeier, M., Hawkins, J. and Cross, I. (Eds.),<emphasis effect="italics"> Language and Music as Cognitive Systems</emphasis>. Oxford: Oxford University Press.</para>
      <para id="id1164172978928">Patel, A.D., and Iversen, J.R. (2007). The linguistic benefits of musical abilities. <emphasis effect="italics">Trends in Cognitive Sciences</emphasis>, 11, 369-372.</para>
      <para id="id1164170324531">Patel, A.D., Iversen, J.R., Chen, Y., and Repp, B.H. (2005). The influence of metricality and modality on synchronization with a beat. <emphasis effect="italics">Experimental Brain Research,</emphasis> 163, 226-238.</para>
      <para id="id1164169877471">Patel, A.D., Iversen, J.R., Wassenaar, M., and Hagoort, P. (2008). Musical syntactic processing in agrammatic Broca’s aphasia. <emphasis effect="italics">Aphasiology</emphasis>, 22, 776-789.</para>
      <para id="id1164170258745">Patel, A.D., Iversen, J.R. Bregman, M.R. and Schulz, I. (2009a). Studying synchronization to a musical beat in nonhuman animals. <emphasis effect="italics">Annals of the New York Academy of Sciences</emphasis>, 1169, 459-469.</para>
      <para id="id1164175886655">Patel, A.D., Iversen, J.R., Bregman, M.R., and Schulz, I. (2009b). Experimental evidence for synchronization to a musical beat in a nonhuman animal. <emphasis effect="italics">Current Biology</emphasis>, 19, 827-830.</para>
      <para id="id1164169610822">Patel, A.D., Iversen, J.R., Bregman, M.R., and Schulz, I. (2009c). Avian and human movement to music: Two further parallels. <emphasis effect="italics">Communicative and Integrative Biology</emphasis>, 2(6), 1-4.</para>
      <para id="id8106700">Patel, A. D., Gibson, E., Ratner, J., Besson, M., and Holcomb, P. (1998). Processing syntactic relations in language and music: An event-related potential study. <emphasis effect="italics">Journal of Cognitive Neuroscience</emphasis>, 10, 717–733.</para>
      <para id="id1164169637362">Peretz, I. (1993). Auditory atonalia for melodies. <emphasis effect="italics">Cognitive Neuropsychology</emphasis>, 10, 21–56.</para>
      <para id="id1164170632420">Peretz, I. (2006). The nature of music from a biological perspective. <emphasis effect="italics">Cognition</emphasis>, 100, 1–32.</para>
      <para id="id1164171268791">Peretz, I. (2010). Towards a neurobiology of musical emotions. In: Juslin, P. and Sloboda, J. (Eds.), <emphasis effect="italics">Handbook of Music and Emotion: Theory, Research, Applications</emphasis> (pp. 99-126). Oxford: Oxford University Press.</para>
      <para id="id8064368">Peretz, I. (in press). Music, language and modularity in action. In: Rebuschat, P., Rohrmeier, M., Hawkins, J., and Cross, I. (Eds.), <emphasis effect="italics">Language and Music as Cognitive Systems</emphasis>. Oxford: Oxford University Press.</para>
      <para id="id1164169561544">Peretz, I. and Coltheart, M. (2003). Modularity of music processing. <emphasis effect="italics">Nature Neuroscience</emphasis>, 6, 688–691.</para>
      <para id="id1164169525384">Peretz, I., Cummings, S., and Dubé, M-P. (2007). The genetics of congenital amusia (or tone-deafness): A family aggregation study. <emphasis effect="italics">American Journal of Human Genetics</emphasis>, 81, 582-588.</para>
      <para id="id1164171040099">Pinker, S. (1997). <emphasis effect="italics">How the Mind Works</emphasis>. London: Allen Lane.</para>
      <para id="id8276139">Pinker, S. (2007). Toward a consilent study of literature. In: Gottschall, J. and Wilson, D.S. (Eds.), <emphasis effect="italics">The Literary Animal: Evolution and the Nature of Narrative</emphasis>. Evanston: Northwestern Univ. Press.</para>
      <para id="id1164170127215">Racette, A., Bard, C., and Peretz, I. (2006). Making non-fluent aphasics speak: Sing along!<emphasis effect="italics"> Brain</emphasis>, 129, 2571–2584.</para>
      <para id="id1164185240832">Reck, D. (1997). <emphasis effect="italics">Music of the Whole Earth</emphasis>. New York: Da Capo Press.</para>
      <para id="id3248065">Rehding, A. (2000). The quest for the origins of music in Germany circa 1900. <emphasis effect="italics">Journal of the American Musicological Society</emphasis>, 53, 345-385.</para>
      <para id="id1164179606870">Reynolds, R. (2005). The evolution of sensibility. <emphasis effect="italics">Nature,</emphasis> 434, 316-319.</para>
      <para id="id1164184070867">Richerson, P.J. and Boyd, R. (2005). <emphasis effect="italics">Not by Genes Alone: How Culture Transformed Human Evolution</emphasis>. Chicago: University of Chicago Press.</para>
      <para id="id1164183729602">Roederer, J.G. (1984). The search for a survival value of music. <emphasis effect="italics">Music Perception</emphasis>, 1, 350-356.</para>
      <para id="id1164173436752">Rohrmeier, M. (2007). A generative approach to diatonic harmonic structure. In: <emphasis effect="italics">Proceedings of the 4th Sound and Music Computing Conference </emphasis>(pp. 97–100). Lefkada, Greece.</para>
      <para id="id7463391">Ross, A. (2007). <emphasis effect="italics">The Rest Is Noise: Listening to the Twentieth Century</emphasis>. London: MacMillan.</para>
      <para id="id1164185521742">Rubin, D. (1995). <emphasis effect="italics">Memory in Oral Traditions: The Cognitive Psychology of Epic, Ballads and Counting-out Rhymes</emphasis>. New York: Oxford University Press.</para>
      <para id="id1164184155777">Sacks, O. (2007). <emphasis effect="italics">Musicophilia: Tales of Music and the Brain.</emphasis> New York: Knopf.</para>
      <para id="id8290587">Salimpoor, V.N., Benovoy, M., Longo, G., Cooperstock, J.R., and Zatorre, R.J. (2009). The rewarding aspects of music listening are related to degree of emotional arousal. <emphasis effect="italics">PLoS One,</emphasis> 4, e7487.</para>
      <para id="id1164174147567">Sammler, D. (2009). The neuroanatomical overlap of syntax processing in music and language: Evidence from lesion and intracranial ERP studies. <emphasis effect="italics">MPI Series in Human Cognitive and Brain Sciences</emphasis>, 108. </para>
      <para id="id1164184659065">Sapolsky, R.M. (2000). Glucocorticoids and hippocampal atrophy in neuropsychiatric disorders. <emphasis effect="italics">Archives of General Psychiatry</emphasis>, 57, 925-935.</para>
      <para id="id1164181607329">Särkämö, T., Tervaniemi, M., Laitinen, S., et al. (2008). Music listening enhances cognitive recovery and mood after middle cerebral artery stroke. <emphasis effect="italics">Brain</emphasis>, 131, 866-876.</para>
      <para id="id1164174220847">Schachner, A., Brady, T.F., Pepperberg, I., and Hauser, M. (2009). Spontaneous motor entrainment to music in multiple vocal mimicking species. <emphasis effect="italics">Current Biology</emphasis>, 19, 831–836.</para>
      <para id="id1164172248353">Schellenberg, E.G. (2004). Music lessons enhance IQ. <emphasis effect="italics">Psychological Science</emphasis>, 15, 511–514.</para>
      <para id="id1164175793183">Schellenberg, E.G. (2006). Exposure to music: The truth about the consequences. In McPherson, G.E.(Ed.), <emphasis effect="italics">The Child as Musician: A Handbook of Musical Development</emphasis> (pp. 111-134). Oxford, UK: Oxford University Press.</para>
      <para id="id1164171089175">Schlaug, G., Forgeard, M., Zhu, L. et al. (2009). Training-induced neuroplasticity in young children. <emphasis effect="italics">Annals of the New York Academy of Sciences</emphasis>, 1169, 205–208.</para>
      <para id="id1164183130115">Schlaug, G., Marchina, S., and Norton, A. (2008). From singing to speaking: Why singing may lead to recovery of expressive language function in patients with Broca’s aphasia. <emphasis effect="italics">Music Perception</emphasis>, 25, 315–323.</para>
      <para id="id7032406">Schlaug, G., Marchina, S., and Norton, A. (2009). Evidence for plasticity in white-matter tracts of patients with chronic Broca’s Aphasia undergoing intense intonation-based speech therapy. <emphasis effect="italics">Annals of the New York Academy of Sciences</emphasis>, 1169, 385-394.</para>
      <para id="id1164172826859">Schneider, P., Scherg, M., Dosch, H.G., et al. (2002). Morphology of Heschl’s gyrus reflects enhanced activation in the auditory cortex of musicians. <emphasis effect="italics">Nature Neuroscience</emphasis>, 5, 688-694.</para>
      <para id="id1164185209720">Slevc, L.R., Rosenberg, J.C., and Patel, A.D. (2009). Making psycholinguistics musical: Self-paced reading time evidence for shared processing of linguistic and musical syntax. <emphasis effect="italics">Psychonomic Bulletin and Review</emphasis>, 16, 374-381.</para>
      <para id="id1164185403841">Sloboda, J. (1985). <emphasis effect="italics">The Musical Mind</emphasis>. Oxford, UK: Oxford University Press.</para>
      <para id="id1164177443297">Smail, D. (2008). <emphasis effect="italics">On Deep History and the Brain</emphasis>. Berkeley: Univ. of California Press.</para>
      <para id="id1164180803537">Snowdon, C. and Teie, D. (2009). Affective responses in tamarins elicited by species-specific music. <emphasis effect="italics">Biology Letters</emphasis> (online ahead of print, doi: 10.1098/rsbl.2009.0593).</para>
      <para id="id1164170617137">Spencer, H. (1857). On the origin and function of music. <emphasis effect="italics">Fraser’s Magazine</emphasis>, Oct. 1857.</para>
      <para id="id1164184068538">Sperber, D. (1996). <emphasis effect="italics">Explaining culture: A Naturalistic Approach</emphasis>. Oxford: Blackwell.</para>
      <para id="id4700094">Steinbeis, N. and Koelsch, S. (2008). Shared neural resources between music and language indicate semantic processing of musical tension-resolution patterns. <emphasis effect="italics">Cerebral Cortex,</emphasis> 18, 1169-1178.</para>
      <para id="id1164184640250">Steinbeis, N., Koelsch, S., and Sloboda, J.A. (2006). The role of harmonic expectancy violations in musical emotions: Evidence from subjective, physiological, and neural responses. <emphasis effect="italics">Journal of Cognitive Neuroscience</emphasis>, 18, 1380–1393. </para>
      <para id="id1164184052038">Stewart, L. (2008). Do musicians have different brains? <emphasis effect="italics">Clinical Medicine,</emphasis> 8, 304-308.</para>
      <para id="id1164183819632">Stewart, L., Henson, R., Kampe, K., et al. (2003). Brain changes after learning to read and play music. <emphasis effect="italics">NeuroImage</emphasis>, 20, 71-83.</para>
      <para id="id1164187429723">Suda, M., Morimoto, K., Obata, A., et al. (2008). Emotional responses to music: Towards scientific perspectives on music therapy. <emphasis effect="italics">Neuroreport</emphasis>, 19, 75-78.</para>
      <para id="id1164171484388">Tallal, P. and Gaab, N. (2006). Dynamic auditory processing, musical experience and language development. <emphasis effect="italics">Trends in Neurosciences</emphasis>, 29, 382–390.</para>
      <para id="id1164185148682">Thomas, D.A. (1995). <emphasis effect="italics">Music and the Origins of Language: Theories from the French Enlightenment</emphasis>. Cambridge: Cambridge University Press.</para>
      <para id="id1164183914334">Thompson, W.F., Schellenberg, E.G., and Husain, G. (2001). Arousal, mood, and the Mozart effect. <emphasis effect="italics">Psychological Science</emphasis>, 12, 248–51.</para>
      <para id="id1164185364296">Tillmann, B., Bharucha, J.J., and Bigand, E. (2000). Implicit learning of tonality: A self-organizing approach. <emphasis effect="italics">Psychological Review</emphasis>,<emphasis effect="italics"/>107, 885–913.</para>
      <para id="id7231258">Tillmann, B., Janata, P., and Bharucha, J.J. (2003). Activation of the inferior frontal cortex in musical priming. <emphasis effect="italics">Cognitive Brain Research</emphasis>, 16, 145–161.</para>
      <para id="id1164185416981">Titon, J.T. (Ed.). (1996). <emphasis effect="italics">Worlds of Music: An Introduction to the Music of the World's Peoples </emphasis>(3rd ed.). New York: Schirmer.</para>
      <para id="id1164172793830">Tomasello, M. (2008). <emphasis effect="italics">Origins of Human Communication</emphasis>. Cambridge, MA: MIT Press.</para>
      <para id="id1164178874833">Trehub, S.E. (2003). The developmental origins of musicality. <emphasis effect="italics">Nature Neuroscience</emphasis>, 6, 669–673.</para>
      <para id="id1164180911569">Trehub, S.E. and Hannon, E.E. (2006). Infant music perception: Domain-general or domain-specific mechanisms? <emphasis effect="italics">Cognition</emphasis>, 100, 73–99.</para>
      <para id="id1164172731315">Trehub, S.E. and Nakata, T. (2002). Emotion and music in infancy. <emphasis effect="italics">Musicae Scientiae</emphasis> (Special Issue), 37-61.</para>
      <para id="id1164179127892">Vitouch, O. and Ladining, O. (2009). <emphasis effect="italics">Music and Evolution.</emphasis> <emphasis effect="italics">Musicae Scientiae</emphasis>, (Special Issue) 2009-2010.</para>
      <para id="id7410325">Wallin, N.L., Merker, B., and Brown, S. (Eds.). (2000). <emphasis effect="italics">The Origins of Music</emphasis>. Cambridge, MA: MIT Press.</para>
      <para id="id1164179728151">Wiltermuth, S.S. and Heath, C. (2009). Synchrony and cooperation. <emphasis effect="italics">Psychological Science</emphasis>, 20, 1-5.</para>
      <para id="id1164179061348">Wilson, D.S., Van Vugt, M., and O’Gorman, R. (2008). Multilevel selection theory and major evolutionary transitions: Implications for psychological science. <emphasis effect="italics">Current Directions in Psychological Science</emphasis>, 17, 6-9.</para>
      <para id="id1164181865677">Wilson, D.S. and Wilson, E.O. (2007). Rethinking the theoretical foundation of sociobiology. <emphasis effect="italics">The Quarterly Review of Biology</emphasis>, 82, 327-348.</para>
      <para id="id1164181865688">Wilson, E.O. (1998). <emphasis effect="italics">Consilience: The Unity of Knowledge</emphasis>. New York: Knopf.</para>
      <para id="id1164174092321">Wong, P.C.M., Skoe, E., Russo, N.M., Dees, T., and Kraus, N. (2007). Musical experience shapes human brainstem encoding of linguistic pitch patterns. <emphasis effect="italics">Nature Neuroscience</emphasis>, 10, 420-422.</para>
      <para id="id1164170271250">Wrangham, R.W. (2009). <emphasis effect="italics">Catching Fire: How Cooking Made us Human. </emphasis>New York: Basic Books.</para>
      <para id="id1164170271264">Zarco, W., Merchant, H., Prado, L., and Mendez, J.C. (2009). Subsecond timing in primates: Comparison of interval production between human subjects and rhesus monkeys. <emphasis effect="italics">Journal of Neurophysiology,</emphasis> 102, 3191–3202.</para>
      <para id="id1164181325730">Zentner, M., Grandjean, D., and Scherer, K.R. (2008). Emotions evoked by the sound of music: Characterization, classification, and measurement. <emphasis effect="italics">Emotion</emphasis>, 8, 494–521.</para>
      <para id="id1164183758258">Zimmerman, M.E., Pan, J.W., Hetherington, H.P., et al. (2008). Hippocampal neurochemistry, neuromorphometry, and verbal memory in non-demented older adults. <emphasis effect="italics">Neurology</emphasis>, 70, 1594–1600.</para>
    </section>
  </content>
</document>